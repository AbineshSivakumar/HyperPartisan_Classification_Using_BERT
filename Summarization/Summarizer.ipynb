{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b97709f-7168-4c82-a8ff-46f554eff059",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/studio-lab-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68f6f0d-433e-4e56-af17-a2344153d249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/studio-lab-user/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median-3000-d9224ad77edfd979/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bc79d4a1c44e47af038f06a64a7a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# data = load_dataset('hyperpartisan_news_detection','byarticle')\n",
    "data = load_dataset(\"maneshkarun/median-3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721400cf-21d7-44af-a12f-adc1e7d21a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias', 'word_count', 'cleaned_data', 'pos_tagged'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05bc107b-c97d-4fae-82c3-647c8a0c9cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f79ba8a-25ce-4fe4-9b70-c0d33257c80c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./.conda/envs/nlp/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow_hub in ./.conda/envs/nlp/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: pandas in ./.conda/envs/nlp/lib/python3.11/site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./.conda/envs/nlp/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: textacy in ./.conda/envs/nlp/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/nlp/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: nltk in ./.conda/envs/nlp/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: transformers in ./.conda/envs/nlp/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: tqdm in ./.conda/envs/nlp/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: matplotlib in ./.conda/envs/nlp/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (0.4.11)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: cachetools>=4.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (5.3.1)\n",
      "Requirement already satisfied: catalogue~=2.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (2.0.8)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (0.12.1)\n",
      "Requirement already satisfied: floret~=0.10.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (0.10.3)\n",
      "Requirement already satisfied: jellyfish>=0.8.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (0.11.2)\n",
      "Requirement already satisfied: networkx>=2.7 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (3.1)\n",
      "Requirement already satisfied: pyphen>=0.10.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (0.14.0)\n",
      "Requirement already satisfied: requests>=2.10.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (2.31.0)\n",
      "Requirement already satisfied: spacy~=3.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from textacy) (3.5.3)\n",
      "Requirement already satisfied: click in ./.conda/envs/nlp/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: toolz>=0.8.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
      "Requirement already satisfied: fsspec in ./.conda/envs/nlp/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests>=2.10.0->textacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests>=2.10.0->textacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests>=2.10.0->textacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests>=2.10.0->textacy) (2023.5.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (2.4.6)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (6.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from spacy~=3.0->textacy) (3.3.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.conda/envs/nlp/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.conda/envs/nlp/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.conda/envs/nlp/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: stanza in ./.conda/envs/nlp/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: emoji in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (2.4.0)\n",
      "Requirement already satisfied: numpy in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (1.23.5)\n",
      "Requirement already satisfied: protobuf in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (4.23.2)\n",
      "Requirement already satisfied: requests in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: six in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (2.0.1)\n",
      "Requirement already satisfied: tqdm in ./.conda/envs/nlp/lib/python3.11/site-packages (from stanza) (4.65.0)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (4.6.3)\n",
      "Requirement already satisfied: sympy in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (1.12)\n",
      "Requirement already satisfied: networkx in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.conda/envs/nlp/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->stanza) (67.7.2)\n",
      "Requirement already satisfied: wheel in ./.conda/envs/nlp/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3.0->stanza) (0.40.0)\n",
      "Requirement already satisfied: cmake in ./.conda/envs/nlp/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.3.0->stanza) (3.26.3)\n",
      "Requirement already satisfied: lit in ./.conda/envs/nlp/lib/python3.11/site-packages (from triton==2.0.0->torch>=1.3.0->stanza) (16.0.5.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->stanza) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->stanza) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->stanza) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.conda/envs/nlp/lib/python3.11/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow_hub pandas scikit-learn textacy numpy nltk transformers tqdm matplotlib\n",
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a978b92c-a57f-429b-8fb3-113eb0874da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.conda/envs/nlp/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: filelock in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.conda/envs/nlp/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in ./.conda/envs/nlp/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/envs/nlp/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nlp/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7604df-9652-4540-9d1d-7dae94402e62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 13:14:33.031164: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-10 13:14:33.687905: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-10 13:14:33.690483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-10 13:14:36.625707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from textacy.datasets.supreme_court import SupremeCourt\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from transformers import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "#from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "import stanza\n",
    "from tensorflow.keras import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import TFRobertaModel,RobertaTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "\n",
    "from numpy.random import seed\n",
    "import random as python_random\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce4ca3-c675-4969-8428-1233d78ff53c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1\n",
      "Number Of Splits\n",
      "2\n",
      "Number Of Words Per Split\n",
      "256.0\n",
      "Min\n",
      "251\n",
      "Max\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "#summarizer = pipeline(\"summarization\",model='facebook/bart-large-cnn',tokenizer='facebook/bart-large-cnn',framework='tf')\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "textfile = open(\"summarized_usdb.txt\", \"w\")\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "# length greater than 2048\n",
    "\n",
    "for row in train_dataset:\n",
    "    count +=1\n",
    "    print(f\"Count: {count}\")\n",
    "    # if count == 5:\n",
    "    #   break\n",
    "    text = row['cleaned_data']\n",
    "    label = row['bias']\n",
    "\n",
    "    # cleaned_text = clean_text(text)\n",
    "    \n",
    "    labels.append(label)\n",
    "    new_sen = text\n",
    "\n",
    "        \n",
    "    if len(new_sen.split())<=512:\n",
    "      print(\"Length of Summarized Final Text\")\n",
    "      print(len(new_sen.split()))\n",
    "      textfile.write(\"--- \"+new_sen + \"\\n\")\n",
    "\n",
    "    else:\n",
    "      n_splits=len(new_sen.split())/1024\n",
    "      n_splits=math.floor(n_splits)\n",
    "      if n_splits==0:\n",
    "          n_splits=1\n",
    "      print(\"Number Of Splits\")\n",
    "      print(n_splits)\n",
    "      n_wordspersplit=512/n_splits\n",
    "      print(\"Number Of Words Per Split\")\n",
    "      print(n_wordspersplit)\n",
    "      net_sum=[]\n",
    "      new_sen=new_sen.split()\n",
    "      for split in range(n_splits):\n",
    "          #print(len(new_sen[split*1025:(split+1)*1025]))\n",
    "          # if len(new_sen[split*1025:(split+1)*1025])<=1024:\n",
    "          #   summarized=new_sen[split*1025:len(new_sen)+1]\n",
    "          #   print(\"Length of Summarized Text\")\n",
    "          #   print(len(new_sen[split*1025:(split+1)*1025]))\n",
    "          #   net_sum.append(summarized)\n",
    "\n",
    "          # else:\n",
    "          #max=round(n_wordspersplit)\n",
    "          #lenplus=len(new_sen.split())+1\n",
    "          # if len(new_sen[split*1025:lenplus])<=n_wordspersplit:\n",
    "          #   print(\"True\")\n",
    "          #   print(split*1025)\n",
    "          #   print(lenplus)\n",
    "          #   min=len(new_sen[split*1025:lenplus])\n",
    "          #   max=len(new_sen[split*1025:lenplus])\n",
    "          # else:\n",
    "          #min=math.floor(n_wordspersplit)\n",
    "          max=math.floor(n_wordspersplit)\n",
    "          min=max-5\n",
    "          print(\"Min\")\n",
    "          print(min)\n",
    "          print(\"Max\")\n",
    "          print(max)\n",
    "          #summarized=summarizer(new_sen[split*1025:(split+1)*1025], min_length=math.floor(n_wordspersplit), max_length=math.floor(n_wordspersplit+10))\n",
    "          #print(len(new_sen[split*512:(split+1)*512]))\n",
    "          #print(new_sen[split*512:(split+1)*512])\n",
    "          temp=' '.join(new_sen[split*1024:(split+1)*1024])\n",
    "          #print(temp)\n",
    "          summarized=summarizer(temp, min_length=min, max_length=max, truncation=True)\n",
    "\n",
    "          #summarized=summarizer(new_sen[split*1024:(split+1)*1024], min_length=min, max_length=max)\n",
    "          #summarized=summarizer(new_sen[split*1025:(split+1)*1025], min_length=166, max_length=176)\n",
    "\n",
    "          print(\"Length of Summarized Split\")\n",
    "          print(len(summarized[0]['summary_text'].split()))\n",
    "\n",
    "          #print(summarized)\n",
    "          #print(summarized[0]['summary_text'])\n",
    "          net_sum.append(summarized[0]['summary_text'])\n",
    "      #summarized = summarizer(new_sen, min_length=450, max_length=500)\n",
    "\n",
    "      new_sen_summary=' '.join(net_sum)\n",
    "      #print(new_sen)\n",
    "      print(\"Length of Summarized Final Text\")\n",
    "      print(len(new_sen_summary.split()))\n",
    "      textfile.write(\"--- \"+new_sen_summary + \"\\n\")\n",
    "      textfile.flush()\n",
    "\n",
    "textfile.close()\n",
    "len_list = [len(ele.split()) for ele in texts]\n",
    "\n",
    "print(labels)\n",
    "print(len(labels))\n",
    "res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n",
    "print(\"Average Length %s\" % res) \n",
    "print('Found %s texts.' % len(texts))\n",
    "print('Found %s labels.' % len(labels_index))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp:Python",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
