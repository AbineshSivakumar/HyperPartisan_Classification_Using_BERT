{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj3gUkvvEZW2"
   },
   "source": [
    "### <font color='blue'>Import all packages</font> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jV9qKCQ3qpl",
    "outputId": "cf68b4eb-84a2-44cd-913b-8e666212d3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DC59AD4KEZW7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/envs/nlp/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import statistics\n",
    "import nltk\n",
    "#from transformers import pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization, Concatenate, Flatten\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras import regularizers\n",
    "#from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import numpy as np\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "import stanza\n",
    "from tensorflow.keras import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import TFRobertaModel,RobertaTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from numpy.random import seed\n",
    "import random as python_random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "np.random.seed(1)\n",
    "python_random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/ubuntu/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median3k_10000s-a12d2bed8c5e7733/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 1/1 [00:00<00:00, 544.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"maneshkarun/median3k_10000s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vccKXcLYEZW-"
   },
   "source": [
    "### <font color='blue'> Preprocessing and cleaning functions </font> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    inps_first_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_second_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_third_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_fourth_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_fifth_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_sixth_512 = Input(shape = (max_len,), dtype='int64')\n",
    "    inps_seventh_512 = Input(shape = (max_len,), dtype='int64')\n",
    "\n",
    "    masks_first_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_second_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_third_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_fourth_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_fifth_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_sixth_512= Input(shape = (max_len,), dtype='int64')\n",
    "    masks_seventh_512= Input(shape = (max_len,), dtype='int64')\n",
    "\n",
    "    dbert_layer_first_512 = dbert_model(inps_first_512, attention_mask=masks_first_512)[0][:,0,:]\n",
    "    dbert_layer_second_512 = dbert_model(inps_second_512, attention_mask=masks_second_512)[0][:,0,:]\n",
    "    dbert_layer_third_512 = dbert_model(inps_third_512, attention_mask=masks_third_512)[0][:,0,:]\n",
    "    dbert_layer_fourth_512 = dbert_model(inps_fourth_512, attention_mask=masks_fourth_512)[0][:,0,:]\n",
    "    dbert_layer_fifth_512 = dbert_model(inps_fifth_512, attention_mask=masks_fifth_512)[0][:,0,:]\n",
    "    dbert_layer_sixth_512 = dbert_model(inps_sixth_512, attention_mask=masks_sixth_512)[0][:,0,:]\n",
    "    dbert_layer_seventh_512 = dbert_model(inps_seventh_512, attention_mask=masks_seventh_512)[0][:,0,:]\n",
    "\n",
    "    concat=Concatenate()([dbert_layer_first_512, dbert_layer_second_512,dbert_layer_third_512, dbert_layer_fourth_512,dbert_layer_fifth_512, dbert_layer_sixth_512,dbert_layer_seventh_512])\n",
    "    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.001))(concat)\n",
    "    dropout_0= Dropout(0.5)(dense_0)\n",
    "    pred = Dense(15, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n",
    "    #pred = Dense(279, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n",
    "    model = tf.keras.Model(inputs=[inps_first_512,masks_first_512,inps_second_512,masks_second_512,inps_third_512,masks_third_512,inps_fourth_512,masks_fourth_512,inps_fifth_512,masks_fifth_512,inps_sixth_512,masks_sixth_512,inps_seventh_512,masks_seventh_512], outputs=pred)\n",
    " \n",
    "    \n",
    "    print(model.summary())\n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 0, 2, 2, 4, 4, 4, 4, 4, 1, 4, 1, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 0, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 4, 2, 4, 1, 4, 4, 2, 2, 0, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 4, 3, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 0, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 4, 2, 4, 2, 2, 2, 4, 2, 3, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 1, 2, 2, 1, 2, 2, 4, 1, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 0, 4, 3, 4, 2, 4, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 3, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 0, 2, 0, 3, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 1, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 3, 4, 4, 4, 4, 2, 4, 4]\n",
      "499\n",
      "Average Length of complete text 3235.1963927855713\n",
      "Found 499 texts in complete\n",
      "Median Length: 3234 \n",
      "Max length of complete text 3273\n",
      "Min length of complete text 3201\n",
      "Average Length of First 512 512.0\n",
      "Average Length of Second 512 512.0\n",
      "Found 499 texts in First 512.\n",
      "Found 499 texts in Second 512.\n",
      "Average Length of Third 512 512.0\n",
      "Average Length of Fourth 512 512.0\n",
      "Found 499 texts in Third 512.\n",
      "Found 499 texts in Fourth 512.\n",
      "Average Length of Fifth 512 512.0\n",
      "Average Length of Sixth 512 512.0\n",
      "Found 499 texts in Fifth 512.\n",
      "Found 499 texts in Sixth 512.\n",
      "Average Length of Seventh 512 512.0\n",
      "Found 499 texts in Seventh 512.\n",
      "Found 5 labels.\n",
      "                                        First_512_text  \\\n",
      "0    You received years of specialized training in ...   \n",
      "1    SEOUL Reuters POSCO 005490KS South Korea8217s ...   \n",
      "2    Photograph by Benjamin Sklar The night he won ...   \n",
      "3    You received years of specialized training in ...   \n",
      "4    Onamp160October 29 The Subcommittee On The Con...   \n",
      "..                                                 ...   \n",
      "494  Occupy Providence was a pivotal event in my li...   \n",
      "495  Veterans and family members of soldiers now in...   \n",
      "496  BEIJING Jan 23 Reuters Volkswagen on Tuesday s...   \n",
      "497  The top US government official in charge of ar...   \n",
      "498  amplta hrefhttpswwwflickrcomphotossoldiersmedi...   \n",
      "\n",
      "                                       Second_512_text  \\\n",
      "0    can8217t forget the things that have happened8...   \n",
      "1    Trade Organization WTO attends an interview wi...   \n",
      "2    of Kentucky and Mike Lee of Utah who are bent ...   \n",
      "3    can8217t forget the things that have happened8...   \n",
      "4    Cooper 360 71513 Zimmerman Trial Jury Instruct...   \n",
      "..                                                 ...   \n",
      "494  from Foucault quick to heart All these and so ...   \n",
      "495  about the campaign his chapter is launching on...   \n",
      "496  plans to announce retaliatory tariffs against ...   \n",
      "497  established the Rumsfeld missile defense commi...   \n",
      "498  Islamic government In a tape that was soon sho...   \n",
      "\n",
      "                                        Third_512_text  \\\n",
      "0    is essentially a superfluous partnership with ...   \n",
      "1    check restrict firearms sales for buyers under...   \n",
      "2    as if you wished Ted might be sick one year so...   \n",
      "3    is essentially a superfluous partnership with ...   \n",
      "4    reasonable means within his power and consiste...   \n",
      "..                                                 ...   \n",
      "494  the opening salvo in a wave of negotiations ov...   \n",
      "495  If they8217re serious about wanting to do some...   \n",
      "496  utility vehicles it also chose to scale back o...   \n",
      "497  War world 8220The dynamics of deterrents are m...   \n",
      "498  weapons of mass destruction or facilities for ...   \n",
      "\n",
      "                                       Fourth_512_text  \\\n",
      "0    before now that state legislatures are effecti...   \n",
      "1    disagree 8220Our eyes are wide open about what...   \n",
      "2    that the 14th Amendment should grant full citi...   \n",
      "3    before now that state legislatures are effecti...   \n",
      "4    600 Homicides Per Yearamp160In a June 2012 stu...   \n",
      "..                                                 ...   \n",
      "494  Middle East In Syria and IsraelPalestine solid...   \n",
      "495  the military a month ago When I ask why Christ...   \n",
      "496  of the Arizona accident are not yet known and ...   \n",
      "497  almost exclusively on proposals for hightech h...   \n",
      "498  Bush administration withdrew from the Kyoto Pr...   \n",
      "\n",
      "                                        Fifth_512_text  \\\n",
      "0    so I don8217t get fined or charged with a misd...   \n",
      "1    stocks sold off earlier on Thursday on the exp...   \n",
      "2    returned to Texas where in 2003 the state8217s...   \n",
      "3    so I don8217t get fined or charged with a misd...   \n",
      "4    Ground laws affect homicides and firearm injur...   \n",
      "..                                                 ...   \n",
      "494  groups like the Libertarian Party can stand as...   \n",
      "495  going on any missions But they continue to kee...   \n",
      "496  to company statements At Uber8217s September 2...   \n",
      "497  and use the weapons it sees fiteven nuclear wa...   \n",
      "498  In the words of the 8220National Security Stra...   \n",
      "\n",
      "                                        Sixth_512_text  \\\n",
      "0    shrinking pool of people who can help women sa...   \n",
      "1    global supply chains that feed companies such ...   \n",
      "2    224 la Ron Paul to eliminate the departments o...   \n",
      "3    shrinking pool of people who can help women sa...   \n",
      "4    of the country Mayors Against Illegal Guns 916...   \n",
      "..                                                 ...   \n",
      "494  it follows as a matter of course that strategy...   \n",
      "495  have many members who actually supported the i...   \n",
      "496  Un has pledged to denuclearize and meet US off...   \n",
      "497  disarmament and arms control to the conviction...   \n",
      "498  to the use of weapons of mass destruction in t...   \n",
      "\n",
      "                                      Seventh_512_text  label  \n",
      "0    and not have it hidden away like something we ...      4  \n",
      "1    businesses like Alphabet Inc Amazoncom Inc and...      2  \n",
      "2    freedom8221 and again gave a shoutout to his d...      4  \n",
      "3    and not have it hidden away like something we ...      4  \n",
      "4    seemed to show that permissive guncarrying law...      4  \n",
      "..                                                 ...    ...  \n",
      "494  the downfalls of Occupy Providence was our fai...      4  \n",
      "495  makers to bully the public is that antiwar pro...      4  \n",
      "496  of Kim Jong Un8217s visit soon became the thir...      2  \n",
      "497  role in the incident that went to the heart of...      4  \n",
      "498  between 1914 and 2001 like all measurements of...      4  \n",
      "\n",
      "[499 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 899kB [00:00, 8.10MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 456kB [00:00, 5.56MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 481/481 [00:00<00:00, 115kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 499M/499M [00:01<00:00, 377MB/s] \n",
      "2023-06-25 16:23:49.021343: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-25 16:23:59.506468: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-06-25 16:23:59.506506: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2023-06-25 16:23:59.506515: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 15, Chunks in use: 15. 3.8KiB allocated for chunks. 3.8KiB in use in bin. 76B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506520: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506525: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506531: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 85, Chunks in use: 85. 261.5KiB allocated for chunks. 261.5KiB in use in bin. 255.0KiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506535: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 9, Chunks in use: 8. 51.5KiB allocated for chunks. 45.5KiB in use in bin. 33.0KiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506540: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 10, Chunks in use: 9. 124.0KiB allocated for chunks. 111.5KiB in use in bin. 108.0KiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506544: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 2, Chunks in use: 2. 46.0KiB allocated for chunks. 46.0KiB in use in bin. 36.0KiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506548: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506552: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 1, Chunks in use: 0. 72.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506556: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506559: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506563: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506567: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 2, Chunks in use: 1. 3.27MiB allocated for chunks. 1.51MiB in use in bin. 1.51MiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506572: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 42, Chunks in use: 40. 95.21MiB allocated for chunks. 90.71MiB in use in bin. 90.00MiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506575: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506580: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 21, Chunks in use: 21. 195.50MiB allocated for chunks. 195.50MiB in use in bin. 189.00MiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506584: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506587: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506591: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506597: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506602: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 1. 258.98MiB allocated for chunks. 258.98MiB in use in bin. 147.26MiB client-requested in use in bin.\n",
      "2023-06-25 16:23:59.506606: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2023-06-25 16:23:59.506609: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 580386816\n",
      "2023-06-25 16:23:59.506616: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000000 of size 256 next 1\n",
      "2023-06-25 16:23:59.506620: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000100 of size 1280 next 2\n",
      "2023-06-25 16:23:59.506622: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000600 of size 256 next 3\n",
      "2023-06-25 16:23:59.506625: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000700 of size 256 next 4\n",
      "2023-06-25 16:23:59.506628: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000800 of size 256 next 5\n",
      "2023-06-25 16:23:59.506631: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000900 of size 256 next 12\n",
      "2023-06-25 16:23:59.506634: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000a00 of size 256 next 14\n",
      "2023-06-25 16:23:59.506637: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000b00 of size 256 next 18\n",
      "2023-06-25 16:23:59.506640: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260000c00 of size 5120 next 7\n",
      "2023-06-25 16:23:59.506643: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260002000 of size 3072 next 8\n",
      "2023-06-25 16:23:59.506646: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260002c00 of size 3072 next 30\n",
      "2023-06-25 16:23:59.506648: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260003800 of size 3072 next 27\n",
      "2023-06-25 16:23:59.506651: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260004400 of size 12288 next 15\n",
      "2023-06-25 16:23:59.506654: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260007400 of size 256 next 19\n",
      "2023-06-25 16:23:59.506657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260007500 of size 5888 next 16\n",
      "2023-06-25 16:23:59.506660: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260008c00 of size 256 next 13\n",
      "2023-06-25 16:23:59.506663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260008d00 of size 256 next 11\n",
      "2023-06-25 16:23:59.506666: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260008e00 of size 256 next 17\n",
      "2023-06-25 16:23:59.506669: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260008f00 of size 256 next 21\n",
      "2023-06-25 16:23:59.506672: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260009000 of size 5376 next 20\n",
      "2023-06-25 16:23:59.506675: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000a500 of size 256 next 23\n",
      "2023-06-25 16:23:59.506677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000a600 of size 256 next 43\n",
      "2023-06-25 16:23:59.506680: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000a700 of size 3072 next 38\n",
      "2023-06-25 16:23:59.506683: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000b300 of size 3072 next 47\n",
      "2023-06-25 16:23:59.506686: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000bf00 of size 5888 next 33\n",
      "2023-06-25 16:23:59.506689: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000d600 of size 256 next 34\n",
      "2023-06-25 16:23:59.506693: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000d700 of size 5888 next 24\n",
      "2023-06-25 16:23:59.506696: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526000ee00 of size 6144 next 25\n",
      "2023-06-25 16:23:59.506699: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260010600 of size 3102208 next 9\n",
      "2023-06-25 16:23:59.506710: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260305c00 of size 1579008 next 10\n",
      "2023-06-25 16:23:59.506713: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260487400 of size 3072 next 28\n",
      "2023-06-25 16:23:59.506716: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260488000 of size 3072 next 37\n",
      "2023-06-25 16:23:59.506719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260488c00 of size 3072 next 45\n",
      "2023-06-25 16:23:59.506722: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260489800 of size 3072 next 49\n",
      "2023-06-25 16:23:59.506724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048a400 of size 3072 next 41\n",
      "2023-06-25 16:23:59.506727: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048b000 of size 3072 next 42\n",
      "2023-06-25 16:23:59.506730: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048bc00 of size 3072 next 52\n",
      "2023-06-25 16:23:59.506733: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048c800 of size 3072 next 54\n",
      "2023-06-25 16:23:59.506736: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048d400 of size 3072 next 50\n",
      "2023-06-25 16:23:59.506739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048e000 of size 3072 next 73\n",
      "2023-06-25 16:23:59.506742: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526048ec00 of size 12800 next 51\n",
      "2023-06-25 16:23:59.506745: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260491e00 of size 3072 next 56\n",
      "2023-06-25 16:23:59.506748: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260492a00 of size 22528 next 60\n",
      "2023-06-25 16:23:59.506751: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260498200 of size 3072 next 61\n",
      "2023-06-25 16:23:59.506753: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260498e00 of size 3072 next 70\n",
      "2023-06-25 16:23:59.506756: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260499a00 of size 3072 next 78\n",
      "2023-06-25 16:23:59.506759: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049a600 of size 3072 next 64\n",
      "2023-06-25 16:23:59.506762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049b200 of size 3072 next 65\n",
      "2023-06-25 16:23:59.506765: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049be00 of size 3072 next 72\n",
      "2023-06-25 16:23:59.506768: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049ca00 of size 3072 next 63\n",
      "2023-06-25 16:23:59.506770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049d600 of size 3072 next 67\n",
      "2023-06-25 16:23:59.506773: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049e200 of size 3584 next 71\n",
      "2023-06-25 16:23:59.506776: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526049f000 of size 12288 next 80\n",
      "2023-06-25 16:23:59.506779: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a2000 of size 3072 next 81\n",
      "2023-06-25 16:23:59.506782: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a2c00 of size 3840 next 75\n",
      "2023-06-25 16:23:59.506785: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a3b00 of size 3072 next 84\n",
      "2023-06-25 16:23:59.506788: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a4700 of size 3072 next 86\n",
      "2023-06-25 16:23:59.506791: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a5300 of size 3072 next 100\n",
      "2023-06-25 16:23:59.506794: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a5f00 of size 3072 next 102\n",
      "2023-06-25 16:23:59.506797: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a6b00 of size 12800 next 85\n",
      "2023-06-25 16:23:59.506800: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604a9d00 of size 3072 next 88\n",
      "2023-06-25 16:23:59.506803: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604aa900 of size 3840 next 90\n",
      "2023-06-25 16:23:59.506806: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ab800 of size 3072 next 82\n",
      "2023-06-25 16:23:59.506809: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ac400 of size 3072 next 91\n",
      "2023-06-25 16:23:59.506812: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ad000 of size 3072 next 94\n",
      "2023-06-25 16:23:59.506814: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604adc00 of size 3072 next 93\n",
      "2023-06-25 16:23:59.506817: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ae800 of size 3072 next 97\n",
      "2023-06-25 16:23:59.506820: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604af400 of size 3072 next 116\n",
      "2023-06-25 16:23:59.506823: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b0000 of size 3072 next 118\n",
      "2023-06-25 16:23:59.506826: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b0c00 of size 12800 next 101\n",
      "2023-06-25 16:23:59.506828: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b3e00 of size 3072 next 104\n",
      "2023-06-25 16:23:59.506831: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b4a00 of size 3840 next 106\n",
      "2023-06-25 16:23:59.506834: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b5900 of size 3072 next 98\n",
      "2023-06-25 16:23:59.506837: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b6500 of size 3072 next 107\n",
      "2023-06-25 16:23:59.506840: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b7100 of size 3072 next 110\n",
      "2023-06-25 16:23:59.506843: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b7d00 of size 3072 next 109\n",
      "2023-06-25 16:23:59.506845: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b8900 of size 3072 next 113\n",
      "2023-06-25 16:23:59.506848: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604b9500 of size 3072 next 132\n",
      "2023-06-25 16:23:59.506851: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ba100 of size 3072 next 134\n",
      "2023-06-25 16:23:59.506854: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604bad00 of size 12800 next 117\n",
      "2023-06-25 16:23:59.506857: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604bdf00 of size 3072 next 120\n",
      "2023-06-25 16:23:59.506860: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604beb00 of size 3840 next 122\n",
      "2023-06-25 16:23:59.506862: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604bfa00 of size 3072 next 114\n",
      "2023-06-25 16:23:59.506865: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c0600 of size 3072 next 123\n",
      "2023-06-25 16:23:59.506868: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c1200 of size 3072 next 126\n",
      "2023-06-25 16:23:59.506871: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c1e00 of size 3072 next 125\n",
      "2023-06-25 16:23:59.506874: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c2a00 of size 3072 next 129\n",
      "2023-06-25 16:23:59.506877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c3600 of size 3072 next 148\n",
      "2023-06-25 16:23:59.506880: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c4200 of size 3072 next 150\n",
      "2023-06-25 16:23:59.506883: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c4e00 of size 12800 next 133\n",
      "2023-06-25 16:23:59.506886: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c8000 of size 3072 next 136\n",
      "2023-06-25 16:23:59.506889: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c8c00 of size 3840 next 138\n",
      "2023-06-25 16:23:59.506892: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604c9b00 of size 3072 next 130\n",
      "2023-06-25 16:23:59.506895: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ca700 of size 3072 next 139\n",
      "2023-06-25 16:23:59.506898: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604cb300 of size 3072 next 142\n",
      "2023-06-25 16:23:59.506900: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604cbf00 of size 3072 next 141\n",
      "2023-06-25 16:23:59.506903: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ccb00 of size 3072 next 145\n",
      "2023-06-25 16:23:59.506907: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604cd700 of size 3072 next 164\n",
      "2023-06-25 16:23:59.506910: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ce300 of size 3072 next 166\n",
      "2023-06-25 16:23:59.506913: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604cef00 of size 12800 next 149\n",
      "2023-06-25 16:23:59.506916: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d2100 of size 3072 next 152\n",
      "2023-06-25 16:23:59.506919: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d2d00 of size 3840 next 154\n",
      "2023-06-25 16:23:59.506922: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d3c00 of size 3072 next 146\n",
      "2023-06-25 16:23:59.506925: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d4800 of size 3072 next 155\n",
      "2023-06-25 16:23:59.506928: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d5400 of size 3072 next 158\n",
      "2023-06-25 16:23:59.506930: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d6000 of size 3072 next 157\n",
      "2023-06-25 16:23:59.506933: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d6c00 of size 3072 next 161\n",
      "2023-06-25 16:23:59.506936: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d7800 of size 3072 next 180\n",
      "2023-06-25 16:23:59.506941: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d8400 of size 3072 next 182\n",
      "2023-06-25 16:23:59.506944: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604d9000 of size 12800 next 165\n",
      "2023-06-25 16:23:59.506947: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604dc200 of size 3072 next 168\n",
      "2023-06-25 16:23:59.506950: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604dce00 of size 3840 next 170\n",
      "2023-06-25 16:23:59.506953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604ddd00 of size 3072 next 162\n",
      "2023-06-25 16:23:59.506956: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604de900 of size 3072 next 171\n",
      "2023-06-25 16:23:59.506959: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604df500 of size 3072 next 174\n",
      "2023-06-25 16:23:59.506962: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e0100 of size 3072 next 173\n",
      "2023-06-25 16:23:59.506965: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e0d00 of size 3072 next 177\n",
      "2023-06-25 16:23:59.506968: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f52604e1900 of size 12800 next 183\n",
      "2023-06-25 16:23:59.506971: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e4b00 of size 6144 next 181\n",
      "2023-06-25 16:23:59.506974: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e6300 of size 3072 next 184\n",
      "2023-06-25 16:23:59.506977: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e6f00 of size 3840 next 186\n",
      "2023-06-25 16:23:59.506980: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f52604e7e00 of size 6144 next 187\n",
      "2023-06-25 16:23:59.506983: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604e9600 of size 6144 next 189\n",
      "2023-06-25 16:23:59.506986: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f52604eae00 of size 73728 next 178\n",
      "2023-06-25 16:23:59.506989: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52604fce00 of size 24576 next 190\n",
      "2023-06-25 16:23:59.506992: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5260502e00 of size 1852928 next 22\n",
      "2023-06-25 16:23:59.506995: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52606c7400 of size 2359296 next 26\n",
      "2023-06-25 16:23:59.506998: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260907400 of size 2359296 next 29\n",
      "2023-06-25 16:23:59.507001: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260b47400 of size 2359296 next 31\n",
      "2023-06-25 16:23:59.507004: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f5260d87400 of size 2359296 next 35\n",
      "2023-06-25 16:23:59.507007: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5260fc7400 of size 2359296 next 36\n",
      "2023-06-25 16:23:59.507010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261207400 of size 2359296 next 44\n",
      "2023-06-25 16:23:59.507013: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261447400 of size 2359296 next 46\n",
      "2023-06-25 16:23:59.507016: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261687400 of size 2359296 next 48\n",
      "2023-06-25 16:23:59.507019: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52618c7400 of size 2359296 next 55\n",
      "2023-06-25 16:23:59.507022: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261b07400 of size 2359296 next 53\n",
      "2023-06-25 16:23:59.507025: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261d47400 of size 2359296 next 62\n",
      "2023-06-25 16:23:59.507028: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5261f87400 of size 2359296 next 68\n",
      "2023-06-25 16:23:59.507031: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f52621c7400 of size 2359296 next 32\n",
      "2023-06-25 16:23:59.507035: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5262407400 of size 9437184 next 39\n",
      "2023-06-25 16:23:59.507038: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5262d07400 of size 9437184 next 40\n",
      "2023-06-25 16:23:59.507042: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5263607400 of size 2359296 next 69\n",
      "2023-06-25 16:23:59.507045: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5263847400 of size 2359296 next 77\n",
      "2023-06-25 16:23:59.507048: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5263a87400 of size 2359296 next 83\n",
      "2023-06-25 16:23:59.507052: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5263cc7400 of size 2359296 next 57\n",
      "2023-06-25 16:23:59.507055: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5263f07400 of size 9437184 next 58\n",
      "2023-06-25 16:23:59.507058: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5264807400 of size 9437184 next 59\n",
      "2023-06-25 16:23:59.507062: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5265107400 of size 2359296 next 87\n",
      "2023-06-25 16:23:59.507065: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5265347400 of size 2359296 next 96\n",
      "2023-06-25 16:23:59.507069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5265587400 of size 2359296 next 99\n",
      "2023-06-25 16:23:59.507072: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52657c7400 of size 2359296 next 74\n",
      "2023-06-25 16:23:59.507076: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5265a07400 of size 9437184 next 66\n",
      "2023-06-25 16:23:59.507080: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5266307400 of size 9437184 next 76\n",
      "2023-06-25 16:23:59.507083: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5266c07400 of size 2359296 next 103\n",
      "2023-06-25 16:23:59.507086: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5266e47400 of size 2359296 next 112\n",
      "2023-06-25 16:23:59.507089: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5267087400 of size 2359296 next 115\n",
      "2023-06-25 16:23:59.507093: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f52672c7400 of size 2359296 next 89\n",
      "2023-06-25 16:23:59.507096: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5267507400 of size 9437184 next 79\n",
      "2023-06-25 16:23:59.507099: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5267e07400 of size 9437184 next 92\n",
      "2023-06-25 16:23:59.507103: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5268707400 of size 2359296 next 119\n",
      "2023-06-25 16:23:59.507106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5268947400 of size 2359296 next 128\n",
      "2023-06-25 16:23:59.507109: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5268b87400 of size 2359296 next 131\n",
      "2023-06-25 16:23:59.507113: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5268dc7400 of size 2359296 next 105\n",
      "2023-06-25 16:23:59.507116: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5269007400 of size 9437184 next 95\n",
      "2023-06-25 16:23:59.507120: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5269907400 of size 9437184 next 108\n",
      "2023-06-25 16:23:59.507123: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526a207400 of size 2359296 next 135\n",
      "2023-06-25 16:23:59.507127: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526a447400 of size 2359296 next 144\n",
      "2023-06-25 16:23:59.507130: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526a687400 of size 2359296 next 147\n",
      "2023-06-25 16:23:59.507133: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526a8c7400 of size 2359296 next 121\n",
      "2023-06-25 16:23:59.507136: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526ab07400 of size 9437184 next 111\n",
      "2023-06-25 16:23:59.507140: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526b407400 of size 9437184 next 124\n",
      "2023-06-25 16:23:59.507143: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526bd07400 of size 2359296 next 151\n",
      "2023-06-25 16:23:59.507147: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526bf47400 of size 2359296 next 160\n",
      "2023-06-25 16:23:59.507150: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526c187400 of size 2359296 next 163\n",
      "2023-06-25 16:23:59.507154: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526c3c7400 of size 2359296 next 137\n",
      "2023-06-25 16:23:59.507160: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526c607400 of size 9437184 next 127\n",
      "2023-06-25 16:23:59.507164: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526cf07400 of size 9437184 next 140\n",
      "2023-06-25 16:23:59.507167: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526d807400 of size 2359296 next 167\n",
      "2023-06-25 16:23:59.507171: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526da47400 of size 2359296 next 176\n",
      "2023-06-25 16:23:59.507177: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526dc87400 of size 2359296 next 179\n",
      "2023-06-25 16:23:59.507180: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526dec7400 of size 2359296 next 153\n",
      "2023-06-25 16:23:59.507184: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526e107400 of size 9437184 next 143\n",
      "2023-06-25 16:23:59.507187: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526ea07400 of size 9437184 next 156\n",
      "2023-06-25 16:23:59.507190: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526f307400 of size 9437184 next 169\n",
      "2023-06-25 16:23:59.507194: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f526fc07400 of size 9437184 next 159\n",
      "2023-06-25 16:23:59.507197: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5270507400 of size 9437184 next 172\n",
      "2023-06-25 16:23:59.507200: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5270e07400 of size 9437184 next 185\n",
      "2023-06-25 16:23:59.507204: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5271707400 of size 16247808 next 6\n",
      "2023-06-25 16:23:59.507208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f5272686000 of size 271556608 next 18446744073709551615\n",
      "2023-06-25 16:23:59.507211: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2023-06-25 16:23:59.507216: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 15 Chunks of size 256 totalling 3.8KiB\n",
      "2023-06-25 16:23:59.507223: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-06-25 16:23:59.507228: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 76 Chunks of size 3072 totalling 228.0KiB\n",
      "2023-06-25 16:23:59.507234: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2023-06-25 16:23:59.507238: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 8 Chunks of size 3840 totalling 30.0KiB\n",
      "2023-06-25 16:23:59.507242: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2023-06-25 16:23:59.507246: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 5376 totalling 5.2KiB\n",
      "2023-06-25 16:23:59.507250: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 5888 totalling 17.2KiB\n",
      "2023-06-25 16:23:59.507254: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 6144 totalling 18.0KiB\n",
      "2023-06-25 16:23:59.507258: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 12288 totalling 24.0KiB\n",
      "2023-06-25 16:23:59.507265: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 12800 totalling 87.5KiB\n",
      "2023-06-25 16:23:59.507269: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 22528 totalling 22.0KiB\n",
      "2023-06-25 16:23:59.507273: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 24576 totalling 24.0KiB\n",
      "2023-06-25 16:23:59.507279: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1579008 totalling 1.51MiB\n",
      "2023-06-25 16:23:59.507284: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 39 Chunks of size 2359296 totalling 87.75MiB\n",
      "2023-06-25 16:23:59.507290: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3102208 totalling 2.96MiB\n",
      "2023-06-25 16:23:59.507294: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 20 Chunks of size 9437184 totalling 180.00MiB\n",
      "2023-06-25 16:23:59.507301: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 16247808 totalling 15.50MiB\n",
      "2023-06-25 16:23:59.507305: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 271556608 totalling 258.98MiB\n",
      "2023-06-25 16:23:59.507312: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 547.14MiB\n",
      "2023-06-25 16:23:59.507315: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 580386816 memory_limit_: 580386816 available bytes: 0 curr_region_allocation_bytes_: 1160773632\n",
      "2023-06-25 16:23:59.507325: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                       580386816\n",
      "InUse:                       573722624\n",
      "MaxInUse:                    580386816\n",
      "NumAllocs:                         825\n",
      "MaxAllocSize:                271556608\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-06-25 16:23:59.507337: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ********************************************************************************xxxxxxxxxxxxxxxxxxxx\n",
      "2023-06-25 16:23:59.507362: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"output\" (type TFRobertaOutput).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received:\n  • hidden_states=tf.Tensor(shape=(1, 2, 3072), dtype=float32)\n  • input_tensor=tf.Tensor(shape=(1, 2, 768), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74389/2643466356.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mdbert_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mdbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFRobertaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mfirst_512_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummarized_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'First_512_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2892\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2894\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msafetensors_from_pt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mrun_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0munpacked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_args_and_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munpacked_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# Keras enforces the first layer argument to be passed, and checks it through `inspect.getfullargspec()`. This\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         )\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             )\n\u001b[1;32m    544\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         layer_output = self.bert_output(\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         )\n\u001b[1;32m    493\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/nlp/lib/python3.7/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, input_tensor, training)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"output\" (type TFRobertaOutput).\n\nfailed to allocate memory [Op:AddV2]\n\nCall arguments received:\n  • hidden_states=tf.Tensor(shape=(1, 2, 3072), dtype=float32)\n  • input_tensor=tf.Tensor(shape=(1, 2, 768), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    texts_complete=[]\n",
    "\n",
    "    texts_0_512 = []  # list of text samples\n",
    "    texts_448_960 = []  # list of text samples\n",
    "    texts_896_1408 = []  # list of text samples\n",
    "    texts_1344_1856 = []  # list of text samples\n",
    "    texts_1792_2304 = []  # list of text samples\n",
    "    texts_2240_2752 = []  # list of text samples\n",
    "    texts_2688_3200 = []  # list of text samples\n",
    "\n",
    "    label_list = []  # list of label ids\n",
    "\n",
    "    count=0\n",
    "\n",
    "    for record in train_data:\n",
    "\n",
    "            #print(record)\n",
    "            new_sen = record['cleaned_data']\n",
    "            new_new_sen = new_sen.split()\n",
    "            \n",
    "            if len(new_new_sen) > 3200:\n",
    "                count=count+1\n",
    "                # print(count)\n",
    "                if count == 500:\n",
    "                    break\n",
    "\n",
    "                label_list.append(record['bias'])\n",
    "\n",
    "                first_512=new_new_sen[0:512]\n",
    "                first_448_960=new_new_sen[448:960]\n",
    "                first_512=' '.join(first_512)\n",
    "                first_448_960=' '.join(first_448_960)\n",
    "\n",
    "                first_896_1408=new_new_sen[896:1408]\n",
    "                first_1344_1856=new_new_sen[1344:1856]\n",
    "                first_896_1408=' '.join(first_896_1408)\n",
    "                first_1344_1856=' '.join(first_1344_1856)\n",
    "\n",
    "                first_1792_2304=new_new_sen[1792:2304]\n",
    "                first_2240_2752=new_new_sen[2240:2752]\n",
    "                first_1792_2304=' '.join(first_1792_2304)\n",
    "                first_2240_2752=' '.join(first_2240_2752)\n",
    "\n",
    "                first_2688_3200=new_new_sen[2688:3200]\n",
    "                first_2688_3200=' '.join(first_2688_3200)\n",
    "\n",
    "                texts_complete.append(new_sen)\n",
    "                texts_0_512.append(first_512)\n",
    "                texts_448_960.append(first_448_960)\n",
    "                texts_896_1408.append(first_896_1408) \n",
    "                texts_1344_1856.append(first_1344_1856) \n",
    "                texts_1792_2304.append(first_1792_2304)  \n",
    "                texts_2240_2752.append(first_2240_2752)\n",
    "                texts_2688_3200.append(first_2688_3200) \n",
    "\n",
    "    len_list_complete = [len(ele.split()) for ele in texts_complete]\n",
    "    len_list_0_512 = [len(ele.split()) for ele in texts_0_512]\n",
    "    len_list_448_960 = [len(ele.split()) for ele in texts_448_960]\n",
    "    len_list_896_1408 = [len(ele.split()) for ele in texts_896_1408]\n",
    "    len_list_1344_1856 = [len(ele.split()) for ele in texts_1344_1856]\n",
    "    len_list_1792_2304 = [len(ele.split()) for ele in texts_1792_2304]\n",
    "    len_list_2240_2752 = [len(ele.split()) for ele in texts_2240_2752]\n",
    "    len_list_2688_3200 = [len(ele.split()) for ele in texts_2688_3200]\n",
    "\n",
    "    print(label_list)\n",
    "    print(len(label_list))\n",
    "\n",
    "\n",
    "    res_complete = 0 if len(len_list_complete) == 0 else (float(sum(len_list_complete)) / len(len_list_complete))\n",
    "    print(\"Average Length of complete text %s\" % res_complete) \n",
    "    print('Found %s texts in complete' % len(texts_complete))\n",
    "    print(\"Median Length: %s \" % statistics.median(len_list_complete))\n",
    "    print(\"Max length of complete text %s\" % max(len_list_complete))\n",
    "    print(\"Min length of complete text %s\" % min(len_list_complete))\n",
    "\n",
    "\n",
    "    res_0_512 = 0 if len(len_list_0_512) == 0 else (float(sum(len_list_0_512)) / len(len_list_0_512))\n",
    "    res_448_960 = 0 if len(len_list_448_960) == 0 else (float(sum(len_list_448_960)) / len(len_list_448_960))\n",
    "    print(\"Average Length of First 512 %s\" % res_0_512) \n",
    "    print(\"Average Length of Second 512 %s\" % res_448_960) \n",
    "    print('Found %s texts in First 512.' % len(texts_0_512))\n",
    "    print('Found %s texts in Second 512.' % len(texts_448_960))\n",
    "\n",
    "    res_896_1408 = 0 if len(len_list_896_1408) == 0 else (float(sum(len_list_896_1408)) / len(len_list_896_1408))\n",
    "    res_1344_1856 = 0 if len(len_list_1344_1856) == 0 else (float(sum(len_list_1344_1856)) / len(len_list_1344_1856))\n",
    "    print(\"Average Length of Third 512 %s\" % res_896_1408) \n",
    "    print(\"Average Length of Fourth 512 %s\" % res_1344_1856) \n",
    "    print('Found %s texts in Third 512.' % len(texts_896_1408))\n",
    "    print('Found %s texts in Fourth 512.' % len(texts_1344_1856))\n",
    "\n",
    "    res_1792_2304 = 0 if len(len_list_1792_2304) == 0 else (float(sum(len_list_1792_2304)) / len(len_list_1792_2304))\n",
    "    res_2240_2752 = 0 if len(len_list_2240_2752) == 0 else (float(sum(len_list_2240_2752)) / len(len_list_2240_2752))\n",
    "    print(\"Average Length of Fifth 512 %s\" % res_1792_2304) \n",
    "    print(\"Average Length of Sixth 512 %s\" % res_2240_2752) \n",
    "    print('Found %s texts in Fifth 512.' % len(texts_1792_2304))\n",
    "    print('Found %s texts in Sixth 512.' % len(texts_2240_2752))\n",
    "\n",
    "    res_2688_3200 = 0 if len(len_list_2688_3200) == 0 else (float(sum(len_list_2688_3200)) / len(len_list_2688_3200))\n",
    "    print(\"Average Length of Seventh 512 %s\" % res_2688_3200)\n",
    "    print('Found %s texts in Seventh 512.' % len(texts_2688_3200))\n",
    "\n",
    "\n",
    "    print('Found %s labels.' % len(set(label_list)))\n",
    "    summarized_data = pd.DataFrame(list(zip(texts_0_512,texts_448_960,texts_896_1408,texts_1344_1856,texts_1792_2304,texts_2240_2752,texts_2688_3200)),\n",
    "               columns =['First_512_text','Second_512_text','Third_512_text','Fourth_512_text','Fifth_512_text','Sixth_512_text', 'Seventh_512_text'])\n",
    "    summarized_data['label'] = label_list\n",
    "    print(summarized_data)\n",
    "    \n",
    "    dbert_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    dbert_model = TFRobertaModel.from_pretrained('roberta-base')\n",
    "    max_len=512\n",
    "    first_512_sentences=summarized_data['First_512_text']\n",
    "    second_512_sentences=summarized_data['Second_512_text']\n",
    "    third_512_sentences=summarized_data['Third_512_text']\n",
    "    fourth_512_sentences=summarized_data['Fourth_512_text']\n",
    "    fifth_512_sentences=summarized_data['Fifth_512_text']\n",
    "    sixth_512_sentences=summarized_data['Sixth_512_text']\n",
    "    seventh_512_sentences=summarized_data['Seventh_512_text']\n",
    "    labels=summarized_data['label']\n",
    "    len(first_512_sentences),len(labels),len(second_512_sentences),len(third_512_sentences),len(fourth_512_sentences),len(fifth_512_sentences),len(sixth_512_sentences),len(seventh_512_sentences)\n",
    "\n",
    "    model_0=create_model()\n",
    "\n",
    "    input_ids_first_512=[]\n",
    "    attention_masks_first_512=[]\n",
    "    for sent in summarized_data['First_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_first_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_first_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_first_512=np.asarray(input_ids_first_512)\n",
    "    attention_masks_first_512=np.array(attention_masks_first_512)\n",
    "    labels=np.array(labels)\n",
    "\n",
    "    input_ids_second_512=[]\n",
    "    attention_masks_second_512=[]\n",
    "    for sent in summarized_data['Second_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_second_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_second_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_second_512=np.asarray(input_ids_second_512)\n",
    "    attention_masks_second_512=np.array(attention_masks_second_512)\n",
    "\n",
    "    input_ids_third_512=[]\n",
    "    attention_masks_third_512=[]\n",
    "    for sent in summarized_data['Third_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_third_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_third_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_third_512=np.asarray(input_ids_third_512)\n",
    "    attention_masks_third_512=np.array(attention_masks_third_512)\n",
    "\n",
    "    input_ids_fourth_512=[]\n",
    "    attention_masks_fourth_512=[]\n",
    "    for sent in summarized_data['Fourth_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_fourth_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_fourth_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_fourth_512=np.asarray(input_ids_fourth_512)\n",
    "    attention_masks_fourth_512=np.array(attention_masks_fourth_512)\n",
    "\n",
    "    input_ids_fifth_512=[]\n",
    "    attention_masks_fifth_512=[]\n",
    "    for sent in summarized_data['Fifth_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_fifth_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_fifth_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_fifth_512=np.asarray(input_ids_fifth_512)\n",
    "    attention_masks_fifth_512=np.array(attention_masks_fifth_512)\n",
    "\n",
    "    input_ids_sixth_512=[]\n",
    "    attention_masks_sixth_512=[]\n",
    "    for sent in summarized_data['Sixth_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_sixth_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_sixth_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_sixth_512=np.asarray(input_ids_sixth_512)\n",
    "    attention_masks_sixth_512=np.array(attention_masks_sixth_512)\n",
    "    \n",
    "    input_ids_seventh_512=[]\n",
    "    attention_masks_seventh_512=[]\n",
    "    for sent in summarized_data['Seventh_512_text']:\n",
    "        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n",
    "        input_ids_seventh_512.append(dbert_inps['input_ids'])\n",
    "        attention_masks_seventh_512.append(dbert_inps['attention_mask'])\n",
    "    input_ids_seventh_512=np.asarray(input_ids_seventh_512)\n",
    "    attention_masks_seventh_512=np.array(attention_masks_seventh_512)\n",
    "\n",
    "    train_inp_first_512,val_inp_first_512,train_label,val_label,train_mask_first_512,val_mask_first_512,train_inp_second_512,val_inp_second_512,train_mask_second_512,val_mask_second_512,train_inp_third_512,val_inp_third_512,train_mask_third_512,val_mask_third_512,train_inp_fourth_512,val_inp_fourth_512,train_mask_fourth_512,val_mask_fourth_512,train_inp_fifth_512,val_inp_fifth_512,train_mask_fifth_512,val_mask_fifth_512,train_inp_sixth_512,val_inp_sixth_512,train_mask_sixth_512,val_mask_sixth_512,train_inp_seventh_512,val_inp_seventh_512,train_mask_seventh_512,val_mask_seventh_512=train_test_split(input_ids_first_512,labels,attention_masks_first_512,input_ids_second_512,attention_masks_second_512,input_ids_third_512,attention_masks_third_512,input_ids_fourth_512,attention_masks_fourth_512,input_ids_fifth_512,attention_masks_fifth_512,input_ids_sixth_512,attention_masks_sixth_512,input_ids_seventh_512,attention_masks_seventh_512,test_size=0.1,random_state=42)\n",
    "\n",
    "    log_dir='dbert_model'\n",
    "\n",
    "    model_save_path='/home/ubuntu/HyperPartisan_Classification_Using_BERT/Stride/roberta-stride64-512-0-5labels.h5'\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "    model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 18 16:50:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    68W / 500W |  79806MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    70W / 500W |  79534MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   4054592      C   python                          79803MiB |\n",
      "|    1   N/A  N/A   4054592      C   python                          79531MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_accuracy=0\n",
    "total_weighted_f1=0\n",
    "total_micro_f1=0\n",
    "total_weighted_precision=0\n",
    "total_micro_precision=0\n",
    "total_weighted_recall=0\n",
    "total_micro_recall=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 16:50:57.172745: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_30270\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:4\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/wol_env/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "INFO:tensorflow:batch_all_reduce: 198 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "INFO:tensorflow:batch_all_reduce: 198 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "948/948 [==============================] - ETA: 0s - loss: 2.6164 - accuracy: 0.5559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 17:01:19.542494: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_270052\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:33\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948/948 [==============================] - 671s 451ms/step - loss: 2.6164 - accuracy: 0.5559 - val_loss: 2.0740 - val_accuracy: 0.7162\n",
      "Epoch 2/5\n",
      "948/948 [==============================] - 391s 413ms/step - loss: 2.0136 - accuracy: 0.7308 - val_loss: 1.9366 - val_accuracy: 0.7470\n",
      "Epoch 3/5\n",
      "948/948 [==============================] - 392s 414ms/step - loss: 1.7874 - accuracy: 0.7929 - val_loss: 1.9202 - val_accuracy: 0.7494\n",
      "Epoch 4/5\n",
      "948/948 [==============================] - 391s 413ms/step - loss: 1.6450 - accuracy: 0.8330 - val_loss: 1.8337 - val_accuracy: 0.7815\n",
      "Epoch 5/5\n",
      "948/948 [==============================] - 390s 412ms/step - loss: 1.5251 - accuracy: 0.8660 - val_loss: 1.8793 - val_accuracy: 0.7755\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "history=model_0.fit([train_inp_first_512,train_mask_first_512,train_inp_second_512,train_mask_second_512,train_inp_third_512,train_mask_third_512,train_inp_fourth_512,train_mask_fourth_512,train_inp_fifth_512,train_mask_fifth_512,train_inp_sixth_512,train_mask_sixth_512,train_inp_seventh_512,train_mask_seventh_512],train_label,batch_size=2,epochs=5,validation_data=([val_inp_first_512,val_mask_first_512,val_inp_second_512,val_mask_second_512,val_inp_third_512,val_mask_third_512,val_inp_fourth_512,val_mask_fourth_512,val_inp_fifth_512,val_mask_fifth_512,val_inp_sixth_512,val_mask_sixth_512,val_inp_seventh_512,val_mask_seventh_512],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_13 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_1[0][0]',                \n",
      " el)                            thPoolingAndCrossAt               'input_8[0][0]',                \n",
      "                                tentions(last_hidde               'input_2[0][0]',                \n",
      "                                n_state=(None, 512,               'input_9[0][0]',                \n",
      "                                 768),                            'input_3[0][0]',                \n",
      "                                 pooler_output=(Non               'input_10[0][0]',               \n",
      "                                e, 768),                          'input_4[0][0]',                \n",
      "                                 past_key_values=No               'input_11[0][0]',               \n",
      "                                ne, hidden_states=N               'input_5[0][0]',                \n",
      "                                one, attentions=Non               'input_12[0][0]',               \n",
      "                                e, cross_attentions               'input_6[0][0]',                \n",
      "                                =None)                            'input_13[0][0]',               \n",
      "                                                                  'input_7[0][0]',                \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_roberta_model[7][0]']       \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_roberta_model[8][0]']       \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 768)         0           ['tf_roberta_model[9][0]']       \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 768)         0           ['tf_roberta_model[10][0]']      \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 768)         0           ['tf_roberta_model[11][0]']      \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 768)         0           ['tf_roberta_model[12][0]']      \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 768)         0           ['tf_roberta_model[13][0]']      \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5376)         0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.__operators__.getitem_1[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          2753024     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 15)           7695        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 127,406,351\n",
      "Trainable params: 127,406,351\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Accuracy: 0.7814726840855107\n",
      "Weighted F1: 0.7804576277451534\n",
      "Micro F1: 0.7814726840855107\n",
      "Weighted Precision: 0.7840091900167567\n",
      "Micro Precision: 0.7814726840855107\n",
      "Weighted Recall: 0.7814726840855107\n",
      "Micro Recall: 0.7814726840855107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/wol_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_labels=[]\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model_saved= create_model()\n",
    "model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n",
    "model_saved.load_weights('/home/ubuntu/HyperPartisan_Classification_Using_BERT/Stride/roberta-stride64-512-0-5labels.h5')\n",
    "\n",
    "for i in range(0,len(val_inp_first_512)):\n",
    "    pred=model_saved.predict([val_inp_first_512[i].reshape(1,512),val_mask_first_512[i].reshape(1,512),val_inp_second_512[i].reshape(1,512),val_mask_second_512[i].reshape(1,512),val_inp_third_512[i].reshape(1,512),val_mask_third_512[i].reshape(1,512),val_inp_fourth_512[i].reshape(1,512),val_mask_fourth_512[i].reshape(1,512),val_inp_fifth_512[i].reshape(1,512),val_mask_fifth_512[i].reshape(1,512),val_inp_sixth_512[i].reshape(1,512),val_mask_sixth_512[i].reshape(1,512),val_inp_seventh_512[i].reshape(1,512),val_mask_seventh_512[i].reshape(1,512)])\n",
    "    pred_label = pred.argmax(axis=1)\n",
    "    pred_labels.append(pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(val_label, pred_labels)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "total_accuracy=total_accuracy+accuracy\n",
    "\n",
    "weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n",
    "print(\"Weighted F1: \"+ str(weighted_f1))\n",
    "total_weighted_f1=total_weighted_f1+weighted_f1\n",
    "micro_f1=f1_score(val_label,pred_labels, average='micro')\n",
    "print(\"Micro F1: \"+ str(micro_f1))\n",
    "total_micro_f1=total_micro_f1+micro_f1\n",
    "\n",
    "weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n",
    "print(\"Weighted Precision: \" + str(weighted_precision))\n",
    "total_weighted_precision=total_weighted_precision+weighted_precision\n",
    "micro_precision=precision_score(val_label, pred_labels, average='micro')\n",
    "print(\"Micro Precision: \" + str(micro_precision))\n",
    "total_micro_precision=total_micro_precision+micro_precision\n",
    "\n",
    "weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n",
    "print(\"Weighted Recall: \" + str(weighted_recall))\n",
    "total_weighted_recall=total_weighted_recall+weighted_recall\n",
    "micro_recall=recall_score(val_label, pred_labels, average='micro')\n",
    "print(\"Micro Recall: \" + str(micro_recall))\n",
    "total_micro_recall=total_micro_recall+micro_recall"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BERT_Concat_15labels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
