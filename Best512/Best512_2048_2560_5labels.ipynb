{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["# %pip install transformers\n","# %pip install sentencepiece\n","# %pip install tensorflow\n","# %pip install stanza\n","# %pip install tensorflow-addons\n","# %pip install nltk\n","# %pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:32:55.727574Z","iopub.status.busy":"2023-06-10T16:32:55.727223Z","iopub.status.idle":"2023-06-10T16:32:55.733741Z","shell.execute_reply":"2023-06-10T16:32:55.732166Z","shell.execute_reply.started":"2023-06-10T16:32:55.727546Z"},"id":"K0rs0NoritMk","outputId":"92b77bac-3521-4e3b-cf37-6f33a0d5c9f1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.7.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:33:56.196950Z","iopub.status.busy":"2023-06-10T16:33:56.196621Z","iopub.status.idle":"2023-06-10T16:34:00.862809Z","shell.execute_reply":"2023-06-10T16:34:00.861709Z","shell.execute_reply.started":"2023-06-10T16:33:56.196919Z"},"id":"wYwcFK5gixXz","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import re\n","import unicodedata\n","import nltk\n","#from transformers import pipeline\n","from nltk.corpus import stopwords\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n","from tqdm import tqdm\n","import pickle\n","from sklearn.metrics import confusion_matrix,f1_score,classification_report\n","import matplotlib.pyplot as plt\n","import itertools\n","from sklearn.utils import shuffle\n","from tensorflow.keras import regularizers\n","#from transformers import *\n","from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n","import pandas as pd\n","from transformers import AutoTokenizer, TFAutoModel\n","import numpy as np\n","import gc\n","import math\n","import json\n","import stanza\n","from tensorflow.keras import *\n","import tensorflow as tf\n","from tensorflow.keras import *\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report\n","from transformers import TFRobertaModel,RobertaTokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.initializers import RandomUniform\n","\n","from numpy.random import seed\n","import random as python_random\n","import os\n","import sys\n","\n","np.random.seed(1)\n","python_random.seed(1)\n","tf.random.set_seed(1)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:00.865328Z","iopub.status.busy":"2023-06-10T16:34:00.864345Z","iopub.status.idle":"2023-06-10T16:34:01.018735Z","shell.execute_reply":"2023-06-10T16:34:01.017444Z","shell.execute_reply.started":"2023-06-10T16:34:00.865284Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/ubuntu/.cache/huggingface/token\n","Login successful\n"]}],"source":["# huggingface dataset access token\n","\n","from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:01.022375Z","iopub.status.busy":"2023-06-10T16:34:01.021954Z","iopub.status.idle":"2023-06-10T16:34:03.631005Z","shell.execute_reply":"2023-06-10T16:34:03.629872Z","shell.execute_reply.started":"2023-06-10T16:34:01.022325Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading readme: 100%|██████████| 654/654 [00:00<00:00, 5.39MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset None/None to /home/ubuntu/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median3k_10000s-a12d2bed8c5e7733/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|██████████| 161M/161M [00:01<00:00, 87.4MB/s]\n","Downloading data: 100%|██████████| 194M/194M [00:02<00:00, 81.7MB/s]\n","Downloading data files: 100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n","Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1195.64it/s]\n","                                                                                      \r"]},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median3k_10000s-a12d2bed8c5e7733/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 625.55it/s]\n"]}],"source":["# importing datasets\n","\n","from datasets import load_dataset\n","# data = load_dataset(\"maneshkarun/median-3000\")\n","data = load_dataset(\"maneshkarun/median3k_10000s\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:03.633820Z","iopub.status.busy":"2023-06-10T16:34:03.632695Z","iopub.status.idle":"2023-06-10T16:34:03.643138Z","shell.execute_reply":"2023-06-10T16:34:03.642212Z","shell.execute_reply.started":"2023-06-10T16:34:03.633782Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias', 'word_count', 'cleaned_data', 'pos_tagged'],\n","        num_rows: 10000\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:03.645409Z","iopub.status.busy":"2023-06-10T16:34:03.644761Z","iopub.status.idle":"2023-06-10T16:34:03.654823Z","shell.execute_reply":"2023-06-10T16:34:03.653814Z","shell.execute_reply.started":"2023-06-10T16:34:03.645374Z"},"trusted":true},"outputs":[],"source":["train_data = data['train']"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:03.657037Z","iopub.status.busy":"2023-06-10T16:34:03.656383Z","iopub.status.idle":"2023-06-10T16:34:03.672843Z","shell.execute_reply":"2023-06-10T16:34:03.671735Z","shell.execute_reply.started":"2023-06-10T16:34:03.657004Z"},"trusted":true},"outputs":[],"source":["train_text = train_data['cleaned_data']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:34:03.675388Z","iopub.status.busy":"2023-06-10T16:34:03.674697Z","iopub.status.idle":"2023-06-10T16:34:03.892540Z","shell.execute_reply":"2023-06-10T16:34:03.891564Z","shell.execute_reply.started":"2023-06-10T16:34:03.675353Z"},"id":"2ZinwFiui-A3","outputId":"1a4d3851-73a3-444b-a286-ec608b7c3197","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 3, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 1, 0, 4, 3, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 1, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 0, 4, 4, 2, 2, 4, 3, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 1, 4, 4, 4, 4, 2, 2, 2, 2, 3, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 3, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 0, 4, 0, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 1, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 0, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 0, 4, 0, 4, 2, 4, 4, 4, 0, 4, 2, 4, 3, 4, 4, 2, 4, 2, 2, 2, 3, 4, 2, 4, 2, 4, 4, 4, 4, 2, 0, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 0, 4, 4, 4, 0, 2, 0, 2, 4, 2, 2, 1, 2, 4, 2, 2, 2, 4, 3, 1, 3, 1, 2, 2, 4, 0, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 0, 2, 2, 0, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 3, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 0, 4, 4, 2, 4, 3, 2, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 0, 4, 1, 4, 2, 4, 0, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4, 1, 4, 4, 2, 2, 4, 2, 0, 4, 3, 2, 3, 0, 2, 2, 2, 2, 4, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 1, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 0, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 0, 4, 2, 4, 1, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0, 1, 4, 2, 4, 2, 2, 0, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 0, 2, 2, 2, 2, 4, 2, 4, 2, 4, 1, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 3, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 0, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 3, 3, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 0, 4, 1, 3, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 2, 1, 2, 4, 4, 4, 2, 3, 2, 4, 0, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 1, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 4, 4, 2, 4, 2, 4, 0, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 3, 4, 4, 4, 4, 2, 2, 2, 4, 1, 2, 4, 4, 4, 2, 2, 4, 0, 3, 4, 4, 4, 2, 4, 4, 4, 3, 3, 4, 4, 4, 2, 4, 3, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 3, 2, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 1, 4, 3, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 0, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 3, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 0, 2, 4, 4, 4, 2, 4, 4, 2, 3, 4, 4, 2, 2, 4, 2, 2, 0, 2, 2, 2, 4, 1, 4, 4, 2, 2, 2, 4, 2, 3, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 3, 2, 2, 2, 4, 4, 4, 4, 2, 4, 3, 4, 4, 1, 4, 2, 2, 4, 2, 4, 4, 0, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 0, 4, 4, 4, 0, 2, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 1, 4, 4, 0, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 0, 2, 2, 4, 4, 2, 2, 2, 3, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 2, 4, 1, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 3, 0, 4, 4, 2, 0, 2, 2, 3, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 3, 3, 4, 4, 1, 4, 2, 4, 2, 4, 3, 4, 4, 4, 2, 2, 4, 4, 0, 3, 2, 2, 4, 4, 2, 4, 2, 1, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 1, 2, 2, 2, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 3, 1, 4, 4, 2, 2, 0, 4, 4, 2, 4, 4, 3, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 0, 4, 2, 0, 2, 2, 4, 4, 0, 0, 4, 2, 2, 2, 1, 0, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 2, 2, 2, 4, 2, 4, 1, 4, 2, 4, 4, 4, 2, 3, 2, 2, 1, 2, 4, 4, 2, 3, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 3, 2, 2, 4, 2, 2, 4, 4, 2, 4, 3, 4, 2, 0, 4, 4, 4, 2, 2, 4, 4, 2, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 0, 1, 4, 2, 4, 2, 2, 1, 2, 4, 2, 4, 2, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 2, 1, 2, 4, 4, 2, 0, 4, 4, 4, 2, 4, 2, 4, 2, 0, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 3, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 1, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 0, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 1, 4, 2, 4, 2, 0, 2, 2, 2, 4, 2, 3, 4, 3, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 3, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 0, 4, 2, 2, 1, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 3, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 3, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 0, 2, 4, 3, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 0, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 1, 2, 2, 3, 2, 2, 2, 2, 2, 1, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 0, 2, 4, 4, 2, 4, 4, 2, 4, 2, 3, 4, 2, 2, 2, 4, 0, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 3, 4, 4, 1, 4, 4, 0, 2, 2, 4, 2, 4, 2, 3, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 1, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 0, 0, 2, 0, 0, 0, 0, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 3, 2, 2, 2, 2, 4, 4, 0, 4, 2, 2, 0, 3, 2, 2, 2, 2, 1, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 0, 0, 4, 4, 4, 4, 3, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 4, 3, 4, 4, 4, 4, 2, 2, 2, 2, 0, 2, 2, 2, 2, 4, 3, 4, 2, 2, 4, 2, 4, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 1, 2, 0, 2, 2, 4, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 0, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 0, 4, 2, 0, 2, 4, 2, 4, 4, 4, 2, 0, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 3, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 4, 3, 2, 2, 2, 2, 2, 4, 4, 2, 2, 0, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 3, 4, 3, 1, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 0, 2, 3, 4, 2, 3, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1, 2, 2, 2, 4, 2, 4, 1, 3, 2, 4, 2, 4, 2, 4, 1, 2, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 3, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 0, 2, 2, 4, 4, 0, 4, 4, 4, 3, 2, 4, 4, 0, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 0, 4, 0, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 4, 0, 2, 4, 2, 2, 2, 4, 4, 3, 4, 4, 2, 2, 2, 4, 4, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 1, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 0, 1, 3, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 1, 1, 2, 1, 1, 2, 2, 0, 1, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 3, 4, 2, 4, 2, 2, 2, 3, 4, 4, 4, 0, 2, 4, 4, 0, 2, 4, 0, 4, 0, 2, 4, 2, 4, 4, 4, 0, 2, 0, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 2, 1, 4, 2, 2, 4, 4, 1, 4, 4, 0, 2, 2, 4, 4, 2, 0, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 0, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 1, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 0, 4, 4, 4, 2, 4, 2, 2, 3, 2, 4, 2, 4, 4, 4, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 3, 4, 4, 3, 3, 4, 4, 4, 2, 4, 2, 4, 2, 0, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 3, 2, 4, 2, 2, 0, 1, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 3, 2, 2, 0, 4, 4, 0, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 1, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 0, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 0, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 2, 3, 4, 2, 4, 4, 3, 4, 2, 2, 2, 4, 4, 4, 0, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 3, 4, 4, 2, 4, 2, 2, 3, 4, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 0, 2, 2, 2, 2, 4, 4, 4, 0, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 0, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0, 2, 0, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 1, 4, 2, 4, 2, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 1, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 4, 2, 4, 2, 2, 2, 0, 2, 4, 3, 4, 4, 2, 4, 0, 4, 4, 2, 2, 4, 3, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 3, 4, 2, 4, 2, 2, 1, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 0, 4, 2, 4, 2, 2, 4, 2, 2, 2, 1, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 1, 4, 2, 4, 2, 2, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 0, 1, 4, 4, 3, 4, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 0, 4, 4, 0, 3, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 3, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 3, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 0, 4, 4, 2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 2, 2, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 2, 0, 1, 4, 2, 4, 1, 2, 4, 3, 4, 0, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 0, 4, 4, 4, 4, 2, 4, 2, 2, 0, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 0, 4, 2, 2, 4, 2, 4, 4, 3, 4, 2, 2, 3, 3, 4, 4, 2, 4, 4, 4, 4, 2, 2, 3, 2, 4, 4, 4, 2, 4, 2, 4, 4, 0, 2, 4, 4, 2, 4, 1, 4, 2, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 0, 2, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 0, 4, 1, 4, 4, 2, 4, 4, 4, 2, 2, 3, 2, 2, 2, 4, 2, 2, 2, 4, 3, 4, 3, 4, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 1, 2, 2, 2, 2, 2, 2, 4, 2, 4, 3, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 2, 4, 1, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 0, 4, 4, 0, 3, 2, 3, 4, 4, 4, 2, 2, 4, 2, 3, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 3, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 0, 2, 2, 4, 4, 4, 4, 4, 1, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 3, 4, 4, 0, 2, 4, 4, 2, 3, 2, 4, 2, 4, 4, 4, 0, 2, 2, 4, 2, 3, 4, 4, 4, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 3, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 3, 4, 2, 4, 4, 2, 2, 4, 1, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 1, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 0, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 4, 4, 2, 4, 4, 4, 0, 2, 2, 4, 2, 4, 2, 2, 4, 0, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 3, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 1, 2, 4, 4, 4, 2, 2, 0, 2, 4, 4, 2, 0, 4, 2, 0, 2, 3, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 3, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 3, 2, 4, 1, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 0, 0, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 1, 0, 2, 4, 2, 3, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 0, 2, 2, 2, 0, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 0, 2, 4, 2, 2, 2, 2, 2, 4, 3, 2, 4, 1, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 0, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 2, 0, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 3, 1, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 2, 2, 2, 2, 2, 0, 4, 2, 2, 4, 2, 4, 1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 3, 0, 0, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 2, 4, 2, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 0, 4, 2, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 0, 2, 4, 1, 4, 1, 4, 4, 2, 4, 0, 2, 4, 4, 4, 2, 4, 0, 1, 2, 2, 2, 4, 0, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 0, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 1, 2, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 2, 2, 2, 1, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 1, 2, 4, 4, 4, 1, 2, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 0, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 1, 4, 2, 4, 2, 3, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 0, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 0, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 0, 4, 2, 2, 2, 2, 4, 2, 2, 3, 4, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 3, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 1, 1, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 3, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 1, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 3, 4, 2, 2, 2, 2, 4, 0, 2, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 3, 4, 2, 2, 0, 4, 0, 2, 4, 1, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 0, 1, 0, 2, 0, 2, 0, 4, 0, 0, 2, 0, 0, 0, 4, 4, 0, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 0, 2, 4, 4, 2, 4, 2, 4, 3, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 1, 4, 4, 4, 4, 0, 4, 3, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 3, 4, 4, 4, 4, 4, 1, 2, 4, 4, 2, 1, 1, 4, 4, 2, 2, 2, 2, 0, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 1, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 2, 2, 4, 1, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 1, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 0, 4, 3, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 2, 4, 2, 4, 4, 0, 1, 4, 4, 4, 2, 2, 4, 3, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 1, 2, 2, 4, 3, 4, 4, 3, 2, 4, 2, 2, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 3, 4, 2, 2, 0, 4, 4, 4, 4, 4, 2, 3, 4, 4, 4, 3, 2, 4, 2, 2, 3, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 1, 2, 4, 2, 1, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 0, 4, 4, 2, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 4, 0, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 3, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 1, 2, 2, 3, 2, 4, 2, 2, 1, 4, 2, 2, 4, 3, 4, 1, 4, 4, 2, 2, 3, 0, 4, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 4, 2, 2, 4, 2, 0, 4, 0, 0, 0, 0, 0, 2, 2, 4, 4, 2, 2, 4, 0, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 2, 4, 4, 2, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 0, 4, 4, 4, 4, 0, 2, 4, 2, 2, 2, 4, 4, 3, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 3, 3, 2, 2, 3, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 0, 4, 4, 2, 2, 2, 0, 0, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 1, 2, 4, 2, 4, 2, 4, 2, 2, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 0, 4, 2, 4, 2, 4, 4, 2, 0, 2, 4, 4, 2, 4, 2, 0, 2, 0, 4, 3, 4, 2, 4, 4, 4, 2, 2, 2, 1, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 0, 4, 2, 2, 4, 2, 2, 4, 2, 2, 0, 0, 4, 0, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 1, 4, 2, 4, 4, 4, 2, 2, 2, 3, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 1, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 0, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 0, 4, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 4, 2, 0, 4, 4, 0, 4, 1, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 3, 4, 2, 0, 2, 2, 1, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 1, 4, 2, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 1, 2, 2, 4, 2, 4, 2, 1, 2, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 0, 1, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 1, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 3, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 0, 2, 4, 2, 2, 3, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 0, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 0, 2, 2, 4, 4, 4, 4, 4, 1, 4, 1, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 0, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 4, 2, 4, 1, 4, 4, 2, 2, 0, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 4, 3, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 0, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 4, 2, 4, 2, 2, 2, 4, 2, 3, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 1, 2, 2, 1, 2, 2, 4, 1, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 0, 4, 3, 4, 2, 4, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 3, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 0, 2, 0, 3, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 1, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 3, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 0, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 3, 2, 2, 4, 2, 4, 4, 4, 4, 4, 0, 2, 2, 2, 4, 2, 3, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 3, 4, 2, 4, 4, 2, 0, 2, 4, 4, 4, 2, 0, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 0, 2, 4, 4, 2, 4, 2, 2, 4, 0, 4, 4, 2, 2, 2, 2, 4, 0, 0, 2, 4, 4, 4, 2, 4, 4, 1, 0, 4, 4, 4, 4, 2, 1, 2, 4, 4, 2, 0, 2, 4, 4, 2, 3, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 3, 4, 4, 2, 4, 2, 4, 4, 3, 4, 2, 2, 4, 4, 2, 1, 0, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 0, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 3, 4, 4, 2, 4, 2, 4, 2, 4, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 1, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 0, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 0, 4, 2, 1, 4, 2, 4, 2, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 1, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 4, 0, 4, 2, 0, 4, 2, 2, 2, 4, 2, 4, 0, 1, 4, 4, 1, 0, 4, 2, 0, 2, 4, 4, 4, 2, 2, 1, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 3, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4, 0, 2, 4, 0, 1, 4, 4, 4, 3, 4, 2, 2, 4, 2, 0, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 0, 1, 4, 3, 4, 2, 2, 2, 3, 3, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 0, 2, 2, 4, 4, 0, 0, 4, 0, 4, 2, 1, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 0, 4, 2, 4, 3, 3, 2, 4, 4, 2, 0, 2, 4, 2, 4, 4, 3, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 0, 4, 0, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 1, 2, 2, 4, 4, 4, 2, 4, 0, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 1, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 3, 2, 2, 4, 2, 2, 0, 2, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 0, 4, 4, 2, 4, 4, 0, 0, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 0, 4, 2, 2, 4, 4, 4, 2, 0, 4, 4, 4, 2, 3, 4, 4, 2, 2, 2, 2, 4, 1, 2, 4, 2, 0, 4, 2, 4, 2, 2, 4, 2, 0, 4, 4, 4, 2, 4, 2, 0, 4, 2, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 1, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 0, 1, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 1, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 0, 0, 4, 4, 4, 2, 3, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 0, 0, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 0, 4, 4, 3, 0, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 4, 0, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 1, 4, 4, 2, 3, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 4, 0, 2, 0, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 3, 4, 4, 4, 0, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 1, 4, 2, 4, 4, 2, 0, 4, 2, 4, 2, 2, 2, 2, 4, 4, 0, 2, 4, 4, 1, 0, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 0, 2, 2, 2, 2, 2, 2, 4, 2, 3, 4, 2, 2, 0, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 3, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 3, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 0, 4, 4, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 3, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 0, 2, 4, 0, 4, 4, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 2, 2, 2, 4, 4, 4, 2, 0, 4, 0, 4, 2, 4, 2, 2, 3, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 3, 2, 4, 4, 2, 0, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 4, 0, 4, 0, 4, 1, 2, 2, 0, 4, 2, 2, 2, 4, 2, 1, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 0, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 3, 4, 4, 3, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 3, 4, 4, 4, 0, 4, 4, 2, 4, 2, 0, 0, 1, 4, 4, 0, 3, 4, 2, 2, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 0, 2, 4, 2, 2, 2, 3, 2, 4, 2, 0, 4, 4, 2, 4, 4, 3, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 0, 2, 4, 2, 0, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 0, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 0, 4, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 3, 0, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 4, 3, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 0, 4, 4, 2, 2, 0, 4, 2, 4, 4, 4, 0, 0, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 4, 2, 2, 4, 1, 2, 2, 4, 4, 0, 4, 0, 4, 4, 4, 0, 1, 3, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 0, 4, 4, 2, 2, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 1, 4, 4, 2, 4, 3, 4, 4, 2, 0, 0, 4, 4, 0, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 1, 4, 0, 4, 2, 1, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 4, 2, 4, 3, 2, 4, 4, 4, 4, 2, 1, 2, 0, 4, 4, 0, 2, 4, 4, 2, 2, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 4, 4, 1, 4, 4, 2, 0, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 2, 4, 4, 2, 4, 4, 4, 0, 2, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 0, 0, 4, 4, 4, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 1, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 0, 4, 0, 2, 0, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 0, 0, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 0, 2, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 2, 2, 4, 0, 4, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 3, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 2, 0, 2, 2, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 0, 4, 3, 4, 4, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 2, 1, 4, 4, 4, 4, 4, 4, 4, 2, 0, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 0, 4, 3, 2, 2, 4, 2, 2, 4, 2, 3, 4, 4, 4, 4, 2, 4, 4, 2, 3, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 3, 4, 4, 0, 2, 4, 4, 4, 4, 0, 2, 0, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 0, 4, 2, 4, 2, 4, 0, 2, 4, 4, 4, 4, 4, 4, 0, 4, 3, 0, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 3, 4, 4, 4, 4, 0, 0, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 3, 4, 4, 1, 0, 4, 2, 2, 0, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 0, 4, 3, 2, 0, 4, 4, 4, 4, 3, 4, 2, 2, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 3, 4, 2, 4, 3, 4, 4, 3, 4, 4, 0, 4, 4, 1, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 0, 2, 4, 4, 4, 4, 4, 0, 0, 4, 1, 4, 4, 4, 3, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 3, 2, 2, 0, 4, 4, 4, 0, 4, 2, 2, 2, 4, 4, 4, 2, 1, 4, 4, 4, 0, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 0, 4, 2, 2, 4]\n","10000\n","Average Length 512.0\n","Found 10000 texts.\n"]}],"source":["texts = []\n","labels = []\n","\n","count=0\n","\n","for record in train_data:\n","    count=count+1\n","    new_sen = record['cleaned_data'].split()\n","    if len(new_sen) >= 2560:\n","        new_sen = new_sen[2048:2560]\n","        \n","    elif len(new_sen) < 512:\n","        new_sen = new_sen[0:len(new_sen)]\n","        \n","    else:\n","        new_sen = new_sen[-512:]\n","          \n","    new_sen = ' '.join(new_sen)\n","\n","    texts.append(new_sen)\n","    labels.append(record['bias'])\n","    \n","len_list = [len(ele.split()) for ele in texts]\n","print(labels)\n","print(len(labels))\n","\n","res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n","\n","print(\"Average Length %s\" % res) \n","print('Found %s texts.' % len(texts))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:34:03.894372Z","iopub.status.busy":"2023-06-10T16:34:03.894044Z","iopub.status.idle":"2023-06-10T16:34:03.914344Z","shell.execute_reply":"2023-06-10T16:34:03.913122Z","shell.execute_reply.started":"2023-06-10T16:34:03.894340Z"},"id":"LprCHRM2aWb8","outputId":"3377113e-6825-4977-bf5d-ac9c08887b56","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                   text  label\n","0     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","1     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","2     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","3     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","4     The race for DNC Chairman was of course totall...      4\n","...                                                 ...    ...\n","9995  for ideological reasons Among those that stand...      0\n","9996  peasant ownership would actually rise from 27 ...      4\n","9997  those of others in a community where victims r...      2\n","9998  those of others in a community where victims r...      2\n","9999  hope that when the Supreme Judicial Court agre...      4\n","\n","[10000 rows x 2 columns]\n"]}],"source":["summarized_data = pd.DataFrame(texts,\n","               columns =['text'])\n","summarized_data['label'] = labels\n","print(summarized_data)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:34:03.918153Z","iopub.status.busy":"2023-06-10T16:34:03.917717Z","iopub.status.idle":"2023-06-10T16:34:03.924638Z","shell.execute_reply":"2023-06-10T16:34:03.923729Z","shell.execute_reply.started":"2023-06-10T16:34:03.918120Z"},"id":"VoY1gHZoaZmG","trusted":true},"outputs":[],"source":["def create_model():\n","    inps = Input(shape = (max_len,), dtype='int64')\n","    masks= Input(shape = (max_len,), dtype='int64')\n","    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n","    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n","    dropout_0= Dropout(0.5)(dense_0)\n","    pred = Dense(5, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n","    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n","    print(model.summary())\n","    return model   "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:34:03.926796Z","iopub.status.busy":"2023-06-10T16:34:03.926180Z","iopub.status.idle":"2023-06-10T16:55:12.223342Z","shell.execute_reply":"2023-06-10T16:55:12.222346Z","shell.execute_reply.started":"2023-06-10T16:34:03.926762Z"},"id":"x9kO4eVwCHKg","outputId":"a3776971-f469-4ae7-dd89-06b3b2630cf1","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)solve/main/vocab.txt: 232kB [00:00, 3.06MB/s]"]},{"name":"stderr","output_type":"stream","text":["\n","Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.56kB/s]\n","Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 750kB/s]\n","Downloading model.safetensors: 100%|██████████| 440M/440M [00:05<00:00, 83.2MB/s] \n","2023-06-25 14:52:31.936364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:31.956457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:31.956589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:31.956950: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-25 14:52:31.958934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:31.959059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:31.959143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:32.367384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:32.367524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:32.367617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 14:52:32.367708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20788 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:06:00.0, compute capability: 8.6\n","2023-06-25 14:52:33.370263: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n","                                thPoolingAndCrossAt               'input_2[0][0]']                \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 512,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 5)            2565        ['dropout_37[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,878,533\n","Trainable params: 109,878,533\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Sun Jun 25 14:54:03 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n","|  0%   41C    P0    57W / 150W |  21548MiB / 23028MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A     70231      C   ...conda/envs/nlp/bin/python    21546MiB |\n","+-----------------------------------------------------------------------------+\n","Epoch 1/5\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","1125/1125 [==============================] - 350s 306ms/step - loss: 5.5929 - accuracy: 0.8664 - val_loss: 4.4923 - val_accuracy: 0.8970\n","Epoch 2/5\n","1125/1125 [==============================] - 346s 308ms/step - loss: 3.6558 - accuracy: 0.9200 - val_loss: 2.9937 - val_accuracy: 0.9140\n","Epoch 3/5\n","1125/1125 [==============================] - 346s 308ms/step - loss: 2.3646 - accuracy: 0.9429 - val_loss: 2.0241 - val_accuracy: 0.9150\n","Epoch 4/5\n","1125/1125 [==============================] - 346s 308ms/step - loss: 1.4918 - accuracy: 0.9638 - val_loss: 1.3991 - val_accuracy: 0.9290\n","Epoch 5/5\n","1125/1125 [==============================] - 346s 307ms/step - loss: 0.9264 - accuracy: 0.9781 - val_loss: 0.9878 - val_accuracy: 0.9280\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n","                                thPoolingAndCrossAt               'input_4[0][0]']                \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 512,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 5)            2565        ['dropout_38[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,878,533\n","Trainable params: 109,878,533\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Accuracy: 0.929\n","Weighted F1: 0.9229921483697854\n","Micro F1: 0.929\n","Weighted Precision: 0.9292934241250211\n","Micro Precision: 0.929\n","Weighted Recall: 0.929\n","Micro Recall: 0.929\n"]}],"source":["from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","total_accuracy=0\n","total_weighted_f1=0\n","total_micro_f1=0\n","total_weighted_precision=0\n","total_micro_precision=0\n","total_weighted_recall=0\n","total_micro_recall=0\n","\n","for i in range(1):\n","    gc.collect()\n","    tf.keras.backend.clear_session()\n","    dbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    dbert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","    max_len=512\n","    sentences=summarized_data['text']\n","    labels=summarized_data['label']\n","    len(sentences),len(labels)\n","    model_0=create_model()\n","    input_ids=[]\n","    attention_masks=[]\n","\n","    for sent in sentences:\n","        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n","        input_ids.append(dbert_inps['input_ids'])\n","        attention_masks.append(dbert_inps['attention_mask'])\n","    input_ids=np.asarray(input_ids)\n","\n","    attention_masks=np.array(attention_masks)\n","    labels=np.array(labels)\n","    train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1,random_state=42)\n","    log_dir='dbert_model'\n","\n","    model_save_path='/home/ubuntu/HyperPartisan_Classification_Using_BERT/Best512' + str(i) + '-5labels.h5'\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","    callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n","    model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n","    gpu_info = !nvidia-smi\n","    gpu_info = '\\n'.join(gpu_info)\n","    if gpu_info.find('failed') >= 0:\n","        print('Not connected to a GPU')\n","    else:\n","        print(gpu_info)\n","    history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n","    pred_labels=[]\n","\n","    model_saved= create_model()\n","    model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n","    model_saved.load_weights('/home/ubuntu/HyperPartisan_Classification_Using_BERT/Best512' + str(i) + '-5labels.h5')\n","\n","    for i in range(0,len(val_inp)):\n","        pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n","        pred_label = pred.argmax(axis=1)\n","        pred_labels.append(pred_label)\n","    accuracy=accuracy_score(val_label, pred_labels)\n","    print(\"Accuracy: \"+str(accuracy))\n","    total_accuracy=total_accuracy+accuracy\n","  \n","    weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n","    print(\"Weighted F1: \"+ str(weighted_f1))\n","    total_weighted_f1=total_weighted_f1+weighted_f1\n","    micro_f1=f1_score(val_label,pred_labels, average='micro')\n","    print(\"Micro F1: \"+ str(micro_f1))\n","    total_micro_f1=total_micro_f1+micro_f1\n","\n","    weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n","    print(\"Weighted Precision: \" + str(weighted_precision))\n","    total_weighted_precision=total_weighted_precision+weighted_precision\n","    micro_precision=precision_score(val_label, pred_labels, average='micro')\n","    print(\"Micro Precision: \" + str(micro_precision))\n","    total_micro_precision=total_micro_precision+micro_precision\n","\n","    weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n","    print(\"Weighted Recall: \" + str(weighted_recall))\n","    total_weighted_recall=total_weighted_recall+weighted_recall\n","    micro_recall=recall_score(val_label, pred_labels, average='micro')\n","    print(\"Micro Recall: \" + str(micro_recall))\n","    total_micro_recall=total_micro_recall+micro_recall\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy: 0.929\n","Average Weighted F1: 0.9229921483697854\n","Average Micro F1: 0.929\n","Average Weighted Precision: 0.9292934241250211\n","Average Micro Precision: 0.929\n","Average Weighted Recall: 0.929\n","Average Micro Recall: 0.929\n"]}],"source":["print(\"Average Accuracy: \"+str(total_accuracy/1))\n","print(\"Average Weighted F1: \"+str(total_weighted_f1/1))\n","print(\"Average Micro F1: \"+str(total_micro_f1/1))\n","print(\"Average Weighted Precision: \"+str(total_weighted_precision/1))\n","print(\"Average Micro Precision: \"+str(total_micro_precision/1))\n","print(\"Average Weighted Recall: \"+str(total_weighted_recall/1))\n","print(\"Average Micro Recall: \"+str(total_micro_recall/1))"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Best-512_0:512_15labels.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":4}
