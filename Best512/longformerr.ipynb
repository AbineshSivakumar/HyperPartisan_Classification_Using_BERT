{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers sentencepiece tensorflow stanza tensorflow-addons nltk textacy datasets ipywidgets","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:03.289966Z","iopub.execute_input":"2023-06-24T16:03:03.290367Z","iopub.status.idle":"2023-06-24T16:03:21.715827Z","shell.execute_reply.started":"2023-06-24T16:03:03.290333Z","shell.execute_reply":"2023-06-24T16:03:21.714709Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.12.0)\nCollecting stanza\n  Downloading stanza-1.5.0-py3-none-any.whl (802 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.10/site-packages (0.20.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting textacy\n  Downloading textacy-0.13.0-py3-none-any.whl (210 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.8)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.31.0)\nRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from stanza) (2.5.0)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.0)\nRequirement already satisfied: typeguard<3.0.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from tensorflow-addons) (2.13.3)\nRequirement already satisfied: cachetools>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (4.2.4)\nRequirement already satisfied: catalogue~=2.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (2.0.8)\nRequirement already satisfied: cytoolz>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from textacy) (0.12.0)\nCollecting floret~=0.10.0 (from textacy)\n  Downloading floret-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (314 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jellyfish>=0.8.0 (from textacy)\n  Downloading jellyfish-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (1.2.0)\nRequirement already satisfied: networkx>=2.7 in /opt/conda/lib/python3.10/site-packages (from textacy) (3.1)\nCollecting pyphen>=0.10.0 (from textacy)\n  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (1.10.1)\nRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (1.2.2)\nRequirement already satisfied: spacy~=3.0 in /opt/conda/lib/python3.10/site-packages (from textacy) (3.5.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (6.23.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.6.4)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.13.2)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (3.0.7)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\nRequirement already satisfied: toolz>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.0)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.3)\nRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.0.2)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.1)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.2)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.38)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.15.1)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\nRequirement already satisfied: ml-dtypes>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0->textacy) (3.1.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (8.1.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (2.4.6)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (0.7.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (0.10.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (6.3.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (1.10.7)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (3.1.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy~=3.0->textacy) (3.3.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (1.12)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.5.0)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\nRequirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.8.0)\nRequirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.5)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.16.0)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.0.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=4.0.0->ipywidgets) (0.2.6)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy~=3.0->textacy) (0.0.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy~=3.0->textacy) (8.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5.0)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.3)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.3)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.17.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.6.2)\nRequirement already satisfied: jupyter-events>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.3)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4.4)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.2.post1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.7)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.3)\nInstalling collected packages: pyphen, jellyfish, floret, stanza, textacy\nSuccessfully installed floret-0.10.3 jellyfish-1.0.0 pyphen-0.14.0 stanza-1.5.0 textacy-0.13.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### LIBRARIES","metadata":{}},{"cell_type":"code","source":"! pip install stanza\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport re\nimport unicodedata\nimport nltk\n\n#from transformers import pipeline\nfrom nltk.corpus import stopwords\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\nfrom tqdm import tqdm\nimport pickle\nfrom sklearn.metrics import confusion_matrix,f1_score,classification_report\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras import regularizers\n\n#from transformers import *\nfrom transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig, TFRobertaModel,RobertaTokenizer\nimport pandas as pd\nfrom transformers import AutoTokenizer, TFAutoModel\nimport numpy as np\nimport gc\nimport math\nimport json\nimport stanza\nfrom tensorflow.keras import *\nimport tensorflow as tf\nfrom tensorflow.keras import *\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report\nfrom transformers import TFRobertaModel,RobertaTokenizer\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.initializers import RandomUniform\nfrom transformers import LongformerTokenizer, TFLongformerModel\nfrom numpy.random import seed\nimport random as python_random\nimport os\nimport sys\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(1)\npython_random.seed(1)\ntf.random.set_seed(1)","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:21.719727Z","iopub.execute_input":"2023-06-24T16:03:21.720022Z","iopub.status.idle":"2023-06-24T16:03:45.757216Z","shell.execute_reply.started":"2023-06-24T16:03:21.719993Z","shell.execute_reply":"2023-06-24T16:03:45.756230Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: stanza in /opt/conda/lib/python3.10/site-packages (1.5.0)\nRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from stanza) (2.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stanza) (1.23.5)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from stanza) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from stanza) (1.16.0)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stanza) (4.64.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DATASET","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\nfrom huggingface_hub import login","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:45.758483Z","iopub.execute_input":"2023-06-24T16:03:45.759231Z","iopub.status.idle":"2023-06-24T16:03:46.264264Z","shell.execute_reply.started":"2023-06-24T16:03:45.759204Z","shell.execute_reply":"2023-06-24T16:03:46.263348Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Access token: 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","metadata":{}},{"cell_type":"code","source":"login()","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:46.267343Z","iopub.execute_input":"2023-06-24T16:03:46.268398Z","iopub.status.idle":"2023-06-24T16:03:46.295009Z","shell.execute_reply.started":"2023-06-24T16:03:46.268370Z","shell.execute_reply":"2023-06-24T16:03:46.294012Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59126b076ea046f6acf3a9a1e768b16b"}},"metadata":{}}]},{"cell_type":"code","source":"data = load_dataset(\"maneshkarun/median-3000\")\ndata","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:46.296617Z","iopub.execute_input":"2023-06-24T16:03:46.297155Z","iopub.status.idle":"2023-06-24T16:03:51.849182Z","shell.execute_reply.started":"2023-06-24T16:03:46.297122Z","shell.execute_reply":"2023-06-24T16:03:51.848257Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset parquet/maneshkarun--median-3000 to /root/.cache/huggingface/datasets/parquet/maneshkarun--median-3000-d9224ad77edfd979/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee3d0afabe90477598e390b969b7f232"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02b5ff674bf45df8ff418eaf14739dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93c4b62c62d2473aaa574e55a6d1c59e"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/maneshkarun--median-3000-d9224ad77edfd979/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebe28f38ea84f8ca0ab1227c80dcca4"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias', 'word_count', 'cleaned_data', 'pos_tagged'],\n        num_rows: 500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"texts_train = data['train']['cleaned_data']\nlabels_train = data['train']['bias']\npos_tagged_train = data['train']['pos_tagged']","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.850795Z","iopub.execute_input":"2023-06-24T16:03:51.851438Z","iopub.status.idle":"2023-06-24T16:03:51.886228Z","shell.execute_reply.started":"2023-06-24T16:03:51.851405Z","shell.execute_reply":"2023-06-24T16:03:51.884713Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"texts = []  # list of text samples\nlabels = []  # list of label ids","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.887567Z","iopub.execute_input":"2023-06-24T16:03:51.887906Z","iopub.status.idle":"2023-06-24T16:03:51.908446Z","shell.execute_reply.started":"2023-06-24T16:03:51.887872Z","shell.execute_reply":"2023-06-24T16:03:51.907526Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"summarized_data = pd.DataFrame(pos_tagged_train,\n               columns =['text'])\nsummarized_data['label'] = labels_train\nprint(summarized_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.910201Z","iopub.execute_input":"2023-06-24T16:03:51.910659Z","iopub.status.idle":"2023-06-24T16:03:51.941932Z","shell.execute_reply.started":"2023-06-24T16:03:51.910628Z","shell.execute_reply":"2023-06-24T16:03:51.940948Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"                                                  text  label\n0    David/PROPN Cay/PROPN Johnston/PROPN was/AUX c...      4\n1    Max/PROPN Blumenthal/PROPN is/AUX an/DET award...      4\n2    Is/AUX President/PROPN Obama8217s/PROPN spendi...      2\n3    A/DET group/NOUN of/ADP Malaysian/ADJ people/N...      4\n4    Advertise/VERB on/ADP MotherJonescom/PROPN Ove...      4\n..                                                 ...    ...\n495  Jessica/PROPN Moore/PROPN showed/VERB up/ADP a...      3\n496  This/PRON is/AUX the/DET second/ADJ part/NOUN ...      4\n497  Like/ADP many/ADJ countries/NOUN trying/VERB t...      4\n498  Whether/SCONJ the/DET fascist/ADJ Marine/PROPN...      4\n499  Standing/VERB at/ADP the/DET front/ADJ door/NO...      3\n\n[500 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"cleaned_data = data['train']['cleaned_data']","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.943711Z","iopub.execute_input":"2023-06-24T16:03:51.944072Z","iopub.status.idle":"2023-06-24T16:03:51.960146Z","shell.execute_reply.started":"2023-06-24T16:03:51.944039Z","shell.execute_reply":"2023-06-24T16:03:51.959318Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"summarized_data2 = pd.DataFrame(cleaned_data,\n               columns =['text'])\nsummarized_data2['label'] = labels_train\nprint(summarized_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.963263Z","iopub.execute_input":"2023-06-24T16:03:51.963586Z","iopub.status.idle":"2023-06-24T16:03:51.972954Z","shell.execute_reply.started":"2023-06-24T16:03:51.963562Z","shell.execute_reply":"2023-06-24T16:03:51.971778Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"                                                  text  label\n0    David/PROPN Cay/PROPN Johnston/PROPN was/AUX c...      4\n1    Max/PROPN Blumenthal/PROPN is/AUX an/DET award...      4\n2    Is/AUX President/PROPN Obama8217s/PROPN spendi...      2\n3    A/DET group/NOUN of/ADP Malaysian/ADJ people/N...      4\n4    Advertise/VERB on/ADP MotherJonescom/PROPN Ove...      4\n..                                                 ...    ...\n495  Jessica/PROPN Moore/PROPN showed/VERB up/ADP a...      3\n496  This/PRON is/AUX the/DET second/ADJ part/NOUN ...      4\n497  Like/ADP many/ADJ countries/NOUN trying/VERB t...      4\n498  Whether/SCONJ the/DET fascist/ADJ Marine/PROPN...      4\n499  Standing/VERB at/ADP the/DET front/ADJ door/NO...      3\n\n[500 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Concatenate\n\ndef create_model():\n    inps = Input(shape=(max_len,), dtype='int64')\n    masks = Input(shape=(max_len,), dtype='int64')\n    longformer_output = longformer_model(inps, attention_mask=masks)\n    sequence_output = longformer_output[0][:, 0, :]\n    pooler_output = longformer_output[1]\n\n    # You can combine the sequence_output and pooler_output in various ways depending\n    # on your use case. Here's an example where we concatenate them:\n    combined_output = Concatenate()([sequence_output, pooler_output])\n\n    # ... then use the combined_output in your model\n    dense_0 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(combined_output)\n    dropout_0 = Dropout(0.5)(dense_0)\n\n    pred = Dense(5, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n    model = tf.keras.Model(inputs=[inps, masks], outputs=pred)\n    print(model.summary())\n    return model\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\ntotal_accuracy=0\ntotal_weighted_f1=0\ntotal_micro_f1=0\ntotal_weighted_precision=0\ntotal_micro_precision=0\ntotal_weighted_recall=0\ntotal_micro_recall=0\n\nfor i in range(5):\n    gc.collect()\n    tf.keras.backend.clear_session()\n    longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n    longformer_model = TFLongformerModel.from_pretrained('allenai/longformer-base-4096')\n    max_len=512\n    sentences=summarized_data['text']\n    labels=summarized_data['label']\n    len(sentences),len(labels)\n    model_0=create_model()\n    input_ids=[]\n    attention_masks=[]\n    \n    for sent in sentences:\n        longformer_inps=longformer_tokenizer.encode_plus(sent,add_special_tokens = True,  max_length =max_len,pad_to_max_length = True,return_attention_mask = True, truncation=True)\n        input_ids.append(longformer_inps['input_ids'])\n        attention_masks.append(longformer_inps['attention_mask'])\n    input_ids=np.asarray(input_ids)\n\n    attention_masks=np.array(attention_masks)\n    labels=np.array(labels)\n    \n\n    train_val_inp, test_inp, train_val_label, test_label, train_val_mask, test_mask = train_test_split(input_ids, labels, attention_masks, test_size=0.2, random_state=42)\n    train_inp, val_inp, train_label, val_label, train_mask, val_mask = train_test_split(train_val_inp, train_val_label, train_val_mask, test_size=0.25, random_state=42)\n    log_dir='dbert_model'\n\n    model_save_path = './kaggle/working/longformer-best-512-0-512-' + str(i) + '-4labels.h5'\n    \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n    accuracy = tf.keras.metrics.BinaryAccuracy()\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,  monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),    keras.callbacks.TensorBoard(log_dir=log_dir)]\n    model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n#     gpu_info = !nvidia-smi\n#     gpu_info = '\\n'.join(gpu_info)\n#     if gpu_info.find('failed') >= 0:\n#           print('Not connected to a GPU')\n#     else:\n#           print(gpu_info)\n\n    pred_labels=[]\n    # Fit the model\n    history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5, validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n    # Save the weights of the trained model\n    model_0.save_weights(model_save_path)\n\n    # Create a new model with the same structure\n    model_saved = create_model()\n\n    # Compile the new model\n    model_saved.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])\n\n    # Load the weights of the trained model into the new model\n    model_saved.load_weights(model_save_path)\n    \n    for i in range(0,len(val_inp)):\n        pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n        pred_label = (pred > 0.5).astype(\"int32\")\n        pred_labels.extend(pred_label.flatten())\n\n    pred_labels = np.array(pred_labels)  # Convert list to numpy array\n    \n    pred = model_saved.predict([val_inp, val_mask])\n\n    # assuming your model is predicting probabilities, take argmax to get the predicted labels\n    pred_labels = np.argmax(pred, axis=1)\n\n\n    accuracy=accuracy_score(val_label, pred_labels)\n    print(\"Accuracy: \"+str(accuracy))\n    total_accuracy=total_accuracy+accuracy\n    \n    weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n    print(\"Weighted F1: \"+ str(weighted_f1))\n    total_weighted_f1=total_weighted_f1+weighted_f1\n    micro_f1=f1_score(val_label,pred_labels, average='micro')\n    print(\"Micro F1: \"+ str(micro_f1))\n    total_micro_f1=total_micro_f1+micro_f1\n\n    weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n    print(\"Weighted Precision: \" + str(weighted_precision))\n    total_weighted_precision=total_weighted_precision+weighted_precision\n    micro_precision=precision_score(val_label, pred_labels, average='micro')\n    print(\"Micro Precision: \" + str(micro_precision))\n    total_micro_precision=total_micro_precision+micro_precision\n\n    weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n    print(\"Weighted Recall: \" + str(weighted_recall))\n    total_weighted_recall=total_weighted_recall+weighted_recall\n    micro_recall=recall_score(val_label, pred_labels, average='micro')\n    print(\"Micro Recall: \" + str(micro_recall))\n    total_micro_recall=total_micro_recall+micro_recall\n\n\nprint(\"Average Accuracy: \"+str(total_accuracy/5))\nprint(\"Average Weighted F1: \"+str(total_weighted_f1/5))\nprint(\"Average Micro F1: \"+str(total_micro_f1/5))\nprint(\"Average Weighted Precision: \"+str(total_weighted_precision/5))\nprint(\"Average Micro Precision: \"+str(total_micro_precision/5))\nprint(\"Average Weighted Recall: \"+str(total_weighted_recall/5))\nprint(\"Average Micro Recall: \"+str(total_micro_recall/5))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-24T16:03:51.974771Z","iopub.execute_input":"2023-06-24T16:03:51.975240Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ba2a515fc8410faef68041523a3210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79f38f48f7e40839137d66448e95511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13e43466906450fa132262ef02a7a70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/765M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db8aa92f9ef4956b4b18f41b0a92b39"}},"metadata":{}},{"name":"stderr","text":"Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 512)]        0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 512)]        0           []                               \n                                                                                                  \n tf_longformer_model (TFLongfor  TFLongformerBaseMod  148659456  ['input_1[0][0]',                \n merModel)                      elOutputWithPooling               'input_2[0][0]']                \n                                (last_hidden_state=                                               \n                                (None, 512, 768),                                                 \n                                 pooler_output=(Non                                               \n                                e, 768),                                                          \n                                 hidden_states=None                                               \n                                , attentions=None,                                                \n                                global_attentions=N                                               \n                                one)                                                              \n                                                                                                  \n tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_longformer_model[0][0]']    \n ingOpLambda)                                                                                     \n                                                                                                  \n concatenate (Concatenate)      (None, 1536)         0           ['tf.__operators__.getitem[0][0]'\n                                                                 , 'tf_longformer_model[0][1]']   \n                                                                                                  \n dense (Dense)                  (None, 512)          786944      ['concatenate[0][0]']            \n                                                                                                  \n dropout_49 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 5)            2565        ['dropout_49[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 149,448,965\nTrainable params: 149,448,965\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/5\n38/38 [==============================] - 208s 2s/step - loss: 8.9568 - binary_accuracy: 0.0213 - val_loss: 8.5841 - val_binary_accuracy: 0.0220\nEpoch 2/5\n38/38 [==============================] - 43s 1s/step - loss: 8.3892 - binary_accuracy: 0.0253 - val_loss: 8.2399 - val_binary_accuracy: 0.0200\nEpoch 3/5\n38/38 [==============================] - 43s 1s/step - loss: 8.0986 - binary_accuracy: 0.0247 - val_loss: 7.9428 - val_binary_accuracy: 0.0200\nEpoch 4/5\n38/38 [==============================] - 42s 1s/step - loss: 7.9848 - binary_accuracy: 0.0240 - val_loss: 7.9306 - val_binary_accuracy: 0.0200\nEpoch 5/5\n38/38 [==============================] - 42s 1s/step - loss: 7.8059 - binary_accuracy: 0.0247 - val_loss: 7.8883 - val_binary_accuracy: 0.0200\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Concatenate\n\ndef create_model():\n    inps = Input(shape=(max_len,), dtype='int64')\n    masks = Input(shape=(max_len,), dtype='int64')\n    longformer_output = longformer_model(inps, attention_mask=masks)\n    sequence_output = longformer_output[0][:, 0, :]\n    pooler_output = longformer_output[1]\n\n    # You can combine the sequence_output and pooler_output in various ways depending\n    # on your use case. Here's an example where we concatenate them:\n    combined_output = Concatenate()([sequence_output, pooler_output])\n\n    # ... then use the combined_output in your model\n    dense_0 = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(combined_output)\n    dropout_0 = Dropout(0.5)(dense_0)\n\n    pred = Dense(5, activation='softmax', kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n    model = tf.keras.Model(inputs=[inps, masks], outputs=pred)\n    print(model.summary())\n    return model\n\n\n\n\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\ntotal_accuracy=0\ntotal_weighted_f1=0\ntotal_micro_f1=0\ntotal_weighted_precision=0\ntotal_micro_precision=0\ntotal_weighted_recall=0\ntotal_micro_recall=0\n\nfor i in range(5):\n    gc.collect()\n    tf.keras.backend.clear_session()\n    longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n    longformer_model = TFLongformerModel.from_pretrained('allenai/longformer-base-4096')\n    max_len=512\n    sentences=summarized_data2['text']\n    labels=summarized_data2['label']\n    len(sentences),len(labels)\n    model_0=create_model()\n    input_ids=[]\n    attention_masks=[]\n    \n    for sent in sentences:\n        longformer_inps=longformer_tokenizer.encode_plus(sent,add_special_tokens = True,  max_length =max_len,pad_to_max_length = True,return_attention_mask = True, truncation=True)\n        input_ids.append(longformer_inps['input_ids'])\n        attention_masks.append(longformer_inps['attention_mask'])\n    input_ids=np.asarray(input_ids)\n\n    attention_masks=np.array(attention_masks)\n    labels=np.array(labels)\n    \n\n    train_val_inp, test_inp, train_val_label, test_label, train_val_mask, test_mask = train_test_split(input_ids, labels, attention_masks, test_size=0.2, random_state=42)\n    train_inp, val_inp, train_label, val_label, train_mask, val_mask = train_test_split(train_val_inp, train_val_label, train_val_mask, test_size=0.25, random_state=42)\n    log_dir='dbert_model'\n\n    model_save_path = './kaggle/working/longformer-best-512-0-512-' + str(i) + '-4labels.h5'\n    \n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n    accuracy = tf.keras.metrics.BinaryAccuracy()\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n    callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,  monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),    keras.callbacks.TensorBoard(log_dir=log_dir)]\n    model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n#     gpu_info = !nvidia-smi\n#     gpu_info = '\\n'.join(gpu_info)\n#     if gpu_info.find('failed') >= 0:\n#           print('Not connected to a GPU')\n#     else:\n#           print(gpu_info)\n\n    pred_labels=[]\n    # Fit the model\n    history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5, validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n    # Save the weights of the trained model\n    model_0.save_weights(model_save_path)\n\n    # Create a new model with the same structure\n    model_saved = create_model()\n\n    # Compile the new model\n    model_saved.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])\n\n    # Load the weights of the trained model into the new model\n    model_saved.load_weights(model_save_path)\n    \n    for i in range(0,len(val_inp)):\n        pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n        pred_label = (pred > 0.5).astype(\"int32\")\n        pred_labels.extend(pred_label.flatten())\n\n    pred_labels = np.array(pred_labels)  # Convert list to numpy array\n    \n    pred = model_saved.predict([val_inp, val_mask])\n\n    # assuming your model is predicting probabilities, take argmax to get the predicted labels\n    pred_labels = np.argmax(pred, axis=1)\n\n\n    accuracy=accuracy_score(val_label, pred_labels)\n    print(\"Accuracy: \"+str(accuracy))\n    total_accuracy=total_accuracy+accuracy\n    \n    weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n    print(\"Weighted F1: \"+ str(weighted_f1))\n    total_weighted_f1=total_weighted_f1+weighted_f1\n    micro_f1=f1_score(val_label,pred_labels, average='micro')\n    print(\"Micro F1: \"+ str(micro_f1))\n    total_micro_f1=total_micro_f1+micro_f1\n\n    weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n    print(\"Weighted Precision: \" + str(weighted_precision))\n    total_weighted_precision=total_weighted_precision+weighted_precision\n    micro_precision=precision_score(val_label, pred_labels, average='micro')\n    print(\"Micro Precision: \" + str(micro_precision))\n    total_micro_precision=total_micro_precision+micro_precision\n\n    weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n    print(\"Weighted Recall: \" + str(weighted_recall))\n    total_weighted_recall=total_weighted_recall+weighted_recall\n    micro_recall=recall_score(val_label, pred_labels, average='micro')\n    print(\"Micro Recall: \" + str(micro_recall))\n    total_micro_recall=total_micro_recall+micro_recall\n\n\nprint(\"Average Accuracy: \"+str(total_accuracy/5))\nprint(\"Average Weighted F1: \"+str(total_weighted_f1/5))\nprint(\"Average Micro F1: \"+str(total_micro_f1/5))\nprint(\"Average Weighted Precision: \"+str(total_weighted_precision/5))\nprint(\"Average Micro Precision: \"+str(total_micro_precision/5))\nprint(\"Average Weighted Recall: \"+str(total_weighted_recall/5))\nprint(\"Average Micro Recall: \"+str(total_micro_recall/5))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}