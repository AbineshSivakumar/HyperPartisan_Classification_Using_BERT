{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:57:53.184910Z","iopub.status.busy":"2023-06-10T16:57:53.184150Z","iopub.status.idle":"2023-06-10T16:58:53.983531Z","shell.execute_reply":"2023-06-10T16:58:53.982271Z","shell.execute_reply.started":"2023-06-10T16:57:53.184873Z"},"trusted":true},"outputs":[],"source":["# %pip install transformers\n","# %pip install sentencepiece\n","# %pip install tensorflow==2.7.0\n","# %pip install stanza\n","# %pip install tensorflow-addons\n","# %pip install nltk\n","# %pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:57:44.483384Z","iopub.status.busy":"2023-06-10T16:57:44.482654Z","iopub.status.idle":"2023-06-10T16:57:53.181859Z","shell.execute_reply":"2023-06-10T16:57:53.180024Z","shell.execute_reply.started":"2023-06-10T16:57:44.483341Z"},"id":"K0rs0NoritMk","outputId":"92b77bac-3521-4e3b-cf37-6f33a0d5c9f1","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.7.0\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:58:53.986012Z","iopub.status.busy":"2023-06-10T16:58:53.985636Z","iopub.status.idle":"2023-06-10T16:58:59.256427Z","shell.execute_reply":"2023-06-10T16:58:59.255495Z","shell.execute_reply.started":"2023-06-10T16:58:53.985971Z"},"id":"wYwcFK5gixXz","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import re\n","import unicodedata\n","import nltk\n","#from transformers import pipeline\n","from nltk.corpus import stopwords\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense,Dropout, Input, BatchNormalization\n","from tqdm import tqdm\n","import pickle\n","from sklearn.metrics import confusion_matrix,f1_score,classification_report\n","import matplotlib.pyplot as plt\n","import itertools\n","from sklearn.utils import shuffle\n","from tensorflow.keras import regularizers\n","#from transformers import *\n","from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n","import pandas as pd\n","from transformers import AutoTokenizer, TFAutoModel\n","import numpy as np\n","import gc\n","import math\n","import json\n","import stanza\n","from tensorflow.keras import *\n","import tensorflow as tf\n","from tensorflow.keras import *\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report\n","from transformers import TFRobertaModel,RobertaTokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.initializers import RandomUniform\n","\n","from numpy.random import seed\n","import random as python_random\n","import os\n","import sys\n","\n","np.random.seed(1)\n","python_random.seed(1)\n","tf.random.set_seed(1)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:58:59.260063Z","iopub.status.busy":"2023-06-10T16:58:59.259319Z","iopub.status.idle":"2023-06-10T16:58:59.642697Z","shell.execute_reply":"2023-06-10T16:58:59.641686Z","shell.execute_reply.started":"2023-06-10T16:58:59.260029Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /home/ubuntu/.cache/huggingface/token\n","Login successful\n"]}],"source":["# huggingface dataset access token\n","\n","from huggingface_hub import login\n","login(token=\"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\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:58:59.645359Z","iopub.status.busy":"2023-06-10T16:58:59.645065Z","iopub.status.idle":"2023-06-10T16:59:02.201904Z","shell.execute_reply":"2023-06-10T16:59:02.200873Z","shell.execute_reply.started":"2023-06-10T16:58:59.645334Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading readme: 100%|██████████| 654/654 [00:00<00:00, 5.51MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset None/None to /home/ubuntu/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median3k_10000s-a12d2bed8c5e7733/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading data: 100%|██████████| 161M/161M [00:01<00:00, 108MB/s]\n","Downloading data: 100%|██████████| 194M/194M [00:01<00:00, 111MB/s]\n","Downloading data files: 100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n","Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1216.80it/s]\n","                                                                                      \r"]},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/maneshkarun___parquet/maneshkarun--median3k_10000s-a12d2bed8c5e7733/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7. Subsequent calls will reuse this data.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 618.45it/s]\n"]}],"source":["# importing datasets\n","\n","from datasets import load_dataset\n","\n","# data = load_dataset(\"maneshkarun/median-3000\")\n","data = load_dataset(\"maneshkarun/median3k_10000s\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:59:02.204755Z","iopub.status.busy":"2023-06-10T16:59:02.203275Z","iopub.status.idle":"2023-06-10T16:59:02.212071Z","shell.execute_reply":"2023-06-10T16:59:02.211181Z","shell.execute_reply.started":"2023-06-10T16:59:02.204719Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'title', 'hyperpartisan', 'url', 'published_at', 'bias', 'word_count', 'cleaned_data', 'pos_tagged'],\n","        num_rows: 10000\n","    })\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:59:02.214263Z","iopub.status.busy":"2023-06-10T16:59:02.213624Z","iopub.status.idle":"2023-06-10T16:59:02.222063Z","shell.execute_reply":"2023-06-10T16:59:02.221188Z","shell.execute_reply.started":"2023-06-10T16:59:02.214230Z"},"trusted":true},"outputs":[],"source":["train_data = data['train']"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:59:02.224251Z","iopub.status.busy":"2023-06-10T16:59:02.223614Z","iopub.status.idle":"2023-06-10T16:59:02.241301Z","shell.execute_reply":"2023-06-10T16:59:02.240389Z","shell.execute_reply.started":"2023-06-10T16:59:02.224199Z"},"trusted":true},"outputs":[],"source":["train_text = train_data['cleaned_data']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:59:02.243503Z","iopub.status.busy":"2023-06-10T16:59:02.242819Z","iopub.status.idle":"2023-06-10T16:59:02.466893Z","shell.execute_reply":"2023-06-10T16:59:02.465865Z","shell.execute_reply.started":"2023-06-10T16:59:02.243469Z"},"id":"2ZinwFiui-A3","outputId":"1a4d3851-73a3-444b-a286-ec608b7c3197","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 3, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 1, 0, 4, 3, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 1, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 0, 4, 4, 2, 2, 4, 3, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 1, 4, 4, 4, 4, 2, 2, 2, 2, 3, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 3, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 0, 4, 0, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 1, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 0, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 0, 4, 0, 4, 2, 4, 4, 4, 0, 4, 2, 4, 3, 4, 4, 2, 4, 2, 2, 2, 3, 4, 2, 4, 2, 4, 4, 4, 4, 2, 0, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 0, 4, 4, 4, 0, 2, 0, 2, 4, 2, 2, 1, 2, 4, 2, 2, 2, 4, 3, 1, 3, 1, 2, 2, 4, 0, 4, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 0, 2, 2, 0, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 3, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 0, 4, 4, 2, 4, 3, 2, 4, 2, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 0, 4, 1, 4, 2, 4, 0, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4, 1, 4, 4, 2, 2, 4, 2, 0, 4, 3, 2, 3, 0, 2, 2, 2, 2, 4, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 1, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 0, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 0, 4, 2, 4, 1, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0, 1, 4, 2, 4, 2, 2, 0, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 0, 2, 2, 2, 2, 4, 2, 4, 2, 4, 1, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 3, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 0, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 3, 3, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 0, 4, 1, 3, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 2, 1, 2, 4, 4, 4, 2, 3, 2, 4, 0, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 1, 4, 3, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 0, 2, 4, 4, 4, 2, 4, 2, 4, 0, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 3, 4, 4, 4, 4, 2, 2, 2, 4, 1, 2, 4, 4, 4, 2, 2, 4, 0, 3, 4, 4, 4, 2, 4, 4, 4, 3, 3, 4, 4, 4, 2, 4, 3, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 3, 2, 4, 4, 1, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 1, 4, 3, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 0, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 3, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 0, 2, 4, 4, 4, 2, 4, 4, 2, 3, 4, 4, 2, 2, 4, 2, 2, 0, 2, 2, 2, 4, 1, 4, 4, 2, 2, 2, 4, 2, 3, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 3, 2, 2, 2, 4, 4, 4, 4, 2, 4, 3, 4, 4, 1, 4, 2, 2, 4, 2, 4, 4, 0, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 0, 4, 4, 4, 0, 2, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 1, 4, 4, 0, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 0, 2, 2, 4, 4, 2, 2, 2, 3, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 2, 4, 1, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 3, 0, 4, 4, 2, 0, 2, 2, 3, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 3, 3, 4, 4, 1, 4, 2, 4, 2, 4, 3, 4, 4, 4, 2, 2, 4, 4, 0, 3, 2, 2, 4, 4, 2, 4, 2, 1, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 1, 2, 2, 2, 4, 3, 2, 4, 2, 4, 4, 2, 4, 2, 3, 1, 4, 4, 2, 2, 0, 4, 4, 2, 4, 4, 3, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 0, 4, 2, 0, 2, 2, 4, 4, 0, 0, 4, 2, 2, 2, 1, 0, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 2, 2, 2, 4, 2, 4, 1, 4, 2, 4, 4, 4, 2, 3, 2, 2, 1, 2, 4, 4, 2, 3, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 3, 2, 2, 4, 2, 2, 4, 4, 2, 4, 3, 4, 2, 0, 4, 4, 4, 2, 2, 4, 4, 2, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 0, 1, 4, 2, 4, 2, 2, 1, 2, 4, 2, 4, 2, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 2, 1, 2, 4, 4, 2, 0, 4, 4, 4, 2, 4, 2, 4, 2, 0, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 3, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 1, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 0, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 1, 4, 2, 4, 2, 0, 2, 2, 2, 4, 2, 3, 4, 3, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 3, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 0, 4, 2, 2, 1, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 3, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 3, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 0, 2, 4, 3, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 0, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 0, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 1, 2, 2, 3, 2, 2, 2, 2, 2, 1, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 0, 2, 4, 4, 2, 4, 4, 2, 4, 2, 3, 4, 2, 2, 2, 4, 0, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 3, 4, 4, 1, 4, 4, 0, 2, 2, 4, 2, 4, 2, 3, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 1, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 0, 0, 2, 0, 0, 0, 0, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 3, 2, 2, 2, 2, 4, 4, 0, 4, 2, 2, 0, 3, 2, 2, 2, 2, 1, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 0, 0, 4, 4, 4, 4, 3, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 4, 3, 4, 4, 4, 4, 2, 2, 2, 2, 0, 2, 2, 2, 2, 4, 3, 4, 2, 2, 4, 2, 4, 2, 4, 1, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 1, 2, 0, 2, 2, 4, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 0, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 0, 4, 2, 0, 2, 4, 2, 4, 4, 4, 2, 0, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 3, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 4, 3, 2, 2, 2, 2, 2, 4, 4, 2, 2, 0, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 3, 4, 3, 1, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 0, 2, 3, 4, 2, 3, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 1, 2, 2, 2, 4, 2, 4, 1, 3, 2, 4, 2, 4, 2, 4, 1, 2, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 3, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 0, 2, 2, 4, 4, 0, 4, 4, 4, 3, 2, 4, 4, 0, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 0, 4, 0, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 4, 0, 2, 4, 2, 2, 2, 4, 4, 3, 4, 4, 2, 2, 2, 4, 4, 2, 4, 3, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 1, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 0, 1, 3, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 1, 1, 2, 1, 1, 2, 2, 0, 1, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 3, 4, 2, 4, 2, 2, 2, 3, 4, 4, 4, 0, 2, 4, 4, 0, 2, 4, 0, 4, 0, 2, 4, 2, 4, 4, 4, 0, 2, 0, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 2, 1, 4, 2, 2, 4, 4, 1, 4, 4, 0, 2, 2, 4, 4, 2, 0, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 0, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 1, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 0, 4, 4, 4, 2, 4, 2, 2, 3, 2, 4, 2, 4, 4, 4, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 3, 4, 4, 3, 3, 4, 4, 4, 2, 4, 2, 4, 2, 0, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 3, 2, 4, 2, 2, 0, 1, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 3, 2, 2, 0, 4, 4, 0, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 1, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 0, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 2, 0, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 2, 3, 4, 2, 4, 4, 3, 4, 2, 2, 2, 4, 4, 4, 0, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 3, 4, 4, 2, 4, 2, 2, 3, 4, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 0, 2, 2, 2, 2, 4, 4, 4, 0, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 0, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 4, 0, 2, 0, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 1, 4, 2, 4, 2, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 1, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 4, 2, 4, 2, 2, 2, 0, 2, 4, 3, 4, 4, 2, 4, 0, 4, 4, 2, 2, 4, 3, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 3, 4, 2, 4, 2, 2, 1, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 0, 4, 2, 4, 2, 2, 4, 2, 2, 2, 1, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 1, 4, 2, 4, 2, 2, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 0, 1, 4, 4, 3, 4, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 0, 4, 4, 0, 3, 4, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 3, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 3, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 0, 4, 4, 2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 2, 2, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 2, 0, 1, 4, 2, 4, 1, 2, 4, 3, 4, 0, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 0, 4, 4, 4, 4, 2, 4, 2, 2, 0, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 0, 4, 2, 2, 4, 2, 4, 4, 3, 4, 2, 2, 3, 3, 4, 4, 2, 4, 4, 4, 4, 2, 2, 3, 2, 4, 4, 4, 2, 4, 2, 4, 4, 0, 2, 4, 4, 2, 4, 1, 4, 2, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 0, 2, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 0, 4, 1, 4, 4, 2, 4, 4, 4, 2, 2, 3, 2, 2, 2, 4, 2, 2, 2, 4, 3, 4, 3, 4, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 1, 2, 2, 2, 2, 2, 2, 4, 2, 4, 3, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 2, 4, 1, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 0, 4, 4, 0, 3, 2, 3, 4, 4, 4, 2, 2, 4, 2, 3, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 3, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 3, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 0, 2, 2, 4, 4, 4, 4, 4, 1, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 2, 4, 3, 4, 4, 0, 2, 4, 4, 2, 3, 2, 4, 2, 4, 4, 4, 0, 2, 2, 4, 2, 3, 4, 4, 4, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 3, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 3, 4, 2, 4, 4, 2, 2, 4, 1, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 1, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 0, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 4, 4, 2, 4, 4, 4, 0, 2, 2, 4, 2, 4, 2, 2, 4, 0, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 3, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 1, 2, 4, 4, 4, 2, 2, 0, 2, 4, 4, 2, 0, 4, 2, 0, 2, 3, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 3, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 3, 2, 4, 1, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 0, 0, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 1, 0, 2, 4, 2, 3, 4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 0, 2, 2, 2, 0, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 0, 2, 4, 2, 2, 2, 2, 2, 4, 3, 2, 4, 1, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 0, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 2, 0, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 3, 1, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 2, 2, 2, 2, 2, 0, 4, 2, 2, 4, 2, 4, 1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 3, 0, 0, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 2, 4, 2, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 0, 4, 2, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 0, 2, 4, 1, 4, 1, 4, 4, 2, 4, 0, 2, 4, 4, 4, 2, 4, 0, 1, 2, 2, 2, 4, 0, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 0, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 1, 2, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 2, 2, 2, 1, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 1, 2, 4, 4, 4, 1, 2, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 0, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 1, 4, 2, 4, 2, 3, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 0, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 0, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 0, 4, 2, 2, 2, 2, 4, 2, 2, 3, 4, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 3, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 1, 1, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 3, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 3, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 1, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 4, 3, 4, 2, 2, 2, 2, 4, 0, 2, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 3, 4, 2, 2, 0, 4, 0, 2, 4, 1, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 0, 1, 0, 2, 0, 2, 0, 4, 0, 0, 2, 0, 0, 0, 4, 4, 0, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 0, 2, 4, 4, 2, 4, 2, 4, 3, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 4, 1, 4, 4, 4, 4, 0, 4, 3, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 3, 4, 4, 4, 4, 4, 1, 2, 4, 4, 2, 1, 1, 4, 4, 2, 2, 2, 2, 0, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 1, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 2, 2, 4, 1, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 1, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 0, 4, 3, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 2, 4, 2, 4, 4, 0, 1, 4, 4, 4, 2, 2, 4, 3, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 1, 2, 2, 4, 3, 4, 4, 3, 2, 4, 2, 2, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 3, 4, 2, 2, 0, 4, 4, 4, 4, 4, 2, 3, 4, 4, 4, 3, 2, 4, 2, 2, 3, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 1, 2, 4, 2, 1, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 0, 4, 4, 2, 2, 2, 4, 4, 4, 0, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 4, 4, 0, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 3, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 1, 2, 2, 3, 2, 4, 2, 2, 1, 4, 2, 2, 4, 3, 4, 1, 4, 4, 2, 2, 3, 0, 4, 0, 2, 0, 1, 2, 0, 0, 2, 0, 0, 4, 2, 2, 4, 2, 0, 4, 0, 0, 0, 0, 0, 2, 2, 4, 4, 2, 2, 4, 0, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 4, 2, 4, 4, 2, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 0, 4, 4, 4, 4, 0, 2, 4, 2, 2, 2, 4, 4, 3, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 3, 3, 2, 2, 3, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 3, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 0, 4, 4, 2, 2, 2, 0, 0, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 1, 2, 4, 2, 4, 2, 4, 2, 2, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 2, 4, 0, 4, 2, 4, 2, 4, 4, 2, 0, 2, 4, 4, 2, 4, 2, 0, 2, 0, 4, 3, 4, 2, 4, 4, 4, 2, 2, 2, 1, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 0, 4, 2, 2, 4, 2, 2, 4, 2, 2, 0, 0, 4, 0, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 1, 4, 2, 4, 4, 4, 2, 2, 2, 3, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 1, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 0, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 0, 4, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 4, 2, 0, 4, 4, 0, 4, 1, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 3, 4, 2, 0, 2, 2, 1, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 1, 4, 2, 4, 2, 4, 2, 2, 4, 2, 2, 3, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 1, 2, 2, 4, 2, 4, 2, 1, 2, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 0, 1, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 1, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 3, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2, 4, 3, 2, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 0, 2, 4, 2, 2, 3, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 0, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 0, 2, 2, 4, 4, 4, 4, 4, 1, 4, 1, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 0, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 4, 2, 4, 1, 4, 4, 2, 2, 0, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 3, 2, 2, 2, 4, 4, 4, 3, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 0, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 3, 2, 4, 2, 4, 2, 2, 2, 4, 2, 3, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 1, 2, 2, 1, 2, 2, 4, 1, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 0, 4, 3, 4, 2, 4, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 3, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 0, 2, 0, 3, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 1, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 0, 3, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 0, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 3, 2, 2, 4, 2, 4, 4, 4, 4, 4, 0, 2, 2, 2, 4, 2, 3, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 3, 4, 2, 4, 4, 2, 0, 2, 4, 4, 4, 2, 0, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 0, 2, 4, 4, 2, 4, 2, 2, 4, 0, 4, 4, 2, 2, 2, 2, 4, 0, 0, 2, 4, 4, 4, 2, 4, 4, 1, 0, 4, 4, 4, 4, 2, 1, 2, 4, 4, 2, 0, 2, 4, 4, 2, 3, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 3, 4, 4, 2, 4, 2, 4, 4, 3, 4, 2, 2, 4, 4, 2, 1, 0, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 0, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 3, 4, 4, 2, 4, 2, 4, 2, 4, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 4, 1, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 0, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 0, 4, 2, 1, 4, 2, 4, 2, 4, 4, 4, 0, 2, 4, 4, 4, 4, 4, 1, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 4, 0, 4, 2, 0, 4, 2, 2, 2, 4, 2, 4, 0, 1, 4, 4, 1, 0, 4, 2, 0, 2, 4, 4, 4, 2, 2, 1, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 3, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 2, 4, 2, 3, 4, 4, 4, 4, 0, 2, 4, 0, 1, 4, 4, 4, 3, 4, 2, 2, 4, 2, 0, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 0, 4, 4, 4, 0, 1, 4, 3, 4, 2, 2, 2, 3, 3, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 0, 2, 2, 4, 4, 0, 0, 4, 0, 4, 2, 1, 4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 0, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 0, 4, 2, 4, 3, 3, 2, 4, 4, 2, 0, 2, 4, 2, 4, 4, 3, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 0, 4, 0, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 1, 2, 2, 4, 4, 4, 2, 4, 0, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 1, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 2, 3, 2, 2, 4, 2, 2, 0, 2, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 0, 4, 4, 2, 4, 4, 0, 0, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 1, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 0, 4, 2, 2, 4, 4, 4, 2, 0, 4, 4, 4, 2, 3, 4, 4, 2, 2, 2, 2, 4, 1, 2, 4, 2, 0, 4, 2, 4, 2, 2, 4, 2, 0, 4, 4, 4, 2, 4, 2, 0, 4, 2, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 1, 4, 4, 4, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 0, 1, 4, 0, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 1, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 0, 0, 4, 4, 4, 2, 3, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 0, 0, 4, 0, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 0, 4, 4, 3, 0, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 4, 0, 2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 0, 4, 1, 4, 4, 2, 3, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 4, 0, 2, 0, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 0, 2, 4, 4, 4, 2, 2, 4, 4, 4, 3, 4, 4, 4, 0, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 1, 4, 2, 4, 4, 2, 0, 4, 2, 4, 2, 2, 2, 2, 4, 4, 0, 2, 4, 4, 1, 0, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 0, 2, 2, 2, 2, 2, 2, 4, 2, 3, 4, 2, 2, 0, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 3, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 3, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 4, 0, 4, 4, 4, 4, 0, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 3, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 0, 2, 4, 0, 4, 4, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 2, 2, 2, 2, 4, 4, 4, 2, 0, 4, 0, 4, 2, 4, 2, 2, 3, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 3, 2, 4, 4, 2, 0, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 4, 0, 4, 0, 4, 1, 2, 2, 0, 4, 2, 2, 2, 4, 2, 1, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 0, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 3, 4, 4, 3, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 1, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 3, 4, 4, 4, 0, 4, 4, 2, 4, 2, 0, 0, 1, 4, 4, 0, 3, 4, 2, 2, 4, 4, 4, 2, 3, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 0, 2, 4, 2, 2, 2, 3, 2, 4, 2, 0, 4, 4, 2, 4, 4, 3, 4, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 0, 2, 4, 2, 0, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 3, 4, 4, 3, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 0, 4, 2, 0, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 0, 4, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 3, 0, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 4, 3, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 2, 0, 4, 4, 2, 2, 0, 4, 2, 4, 4, 4, 0, 0, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 3, 4, 4, 2, 2, 4, 1, 2, 2, 4, 4, 0, 4, 0, 4, 4, 4, 0, 1, 3, 4, 4, 4, 2, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 0, 4, 4, 2, 2, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 1, 4, 4, 2, 4, 3, 4, 4, 2, 0, 0, 4, 4, 0, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 1, 4, 0, 4, 2, 1, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 1, 4, 2, 4, 3, 2, 4, 4, 4, 4, 2, 1, 2, 0, 4, 4, 0, 2, 4, 4, 2, 2, 4, 2, 4, 4, 0, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 4, 0, 0, 4, 0, 0, 0, 4, 0, 0, 2, 4, 4, 1, 4, 4, 2, 0, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 3, 4, 4, 2, 4, 4, 2, 4, 4, 4, 0, 2, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 0, 0, 4, 4, 4, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 1, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 0, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 0, 4, 0, 2, 0, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 0, 0, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 0, 2, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 2, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 0, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 0, 2, 2, 4, 0, 4, 4, 2, 4, 4, 0, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 3, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 2, 0, 2, 2, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 0, 4, 3, 4, 4, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 2, 1, 4, 4, 4, 4, 4, 4, 4, 2, 0, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 0, 4, 3, 2, 2, 4, 2, 2, 4, 2, 3, 4, 4, 4, 4, 2, 4, 4, 2, 3, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 3, 4, 4, 0, 2, 4, 4, 4, 4, 0, 2, 0, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 0, 4, 2, 4, 2, 4, 0, 2, 4, 4, 4, 4, 4, 4, 0, 4, 3, 0, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 2, 4, 2, 4, 3, 4, 4, 4, 4, 0, 0, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 3, 4, 4, 1, 0, 4, 2, 2, 0, 2, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 0, 4, 3, 2, 0, 4, 4, 4, 4, 3, 4, 2, 2, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 0, 0, 4, 4, 4, 4, 4, 3, 4, 2, 4, 3, 4, 4, 3, 4, 4, 0, 4, 4, 1, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 0, 2, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 0, 2, 4, 4, 4, 4, 4, 0, 0, 4, 1, 4, 4, 4, 3, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 3, 2, 2, 0, 4, 4, 4, 0, 4, 2, 2, 2, 4, 4, 4, 2, 1, 4, 4, 4, 0, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 0, 4, 2, 2, 4]\n","10000\n","Average Length 512.0\n","Found 10000 texts.\n"]}],"source":["texts = []\n","labels = []\n","\n","count=0\n","\n","for record in train_data:\n","    count=count+1\n","    new_sen = record['cleaned_data'].split()\n","    if len(new_sen) >= 3072:\n","        new_sen = new_sen[2560:3072]\n","        \n","    elif len(new_sen) < 512:\n","        new_sen = new_sen[0:len(new_sen)]\n","        \n","    else:\n","        new_sen = new_sen[-512:]\n","          \n","    new_sen = ' '.join(new_sen)\n","\n","    texts.append(new_sen)\n","    labels.append(record['bias'])\n","    \n","len_list = [len(ele.split()) for ele in texts]\n","print(labels)\n","print(len(labels))\n","\n","res = 0 if len(len_list) == 0 else (float(sum(len_list)) / len(len_list))\n","\n","print(\"Average Length %s\" % res) \n","print('Found %s texts.' % len(texts))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:59:02.468738Z","iopub.status.busy":"2023-06-10T16:59:02.468409Z","iopub.status.idle":"2023-06-10T16:59:02.486099Z","shell.execute_reply":"2023-06-10T16:59:02.484898Z","shell.execute_reply.started":"2023-06-10T16:59:02.468707Z"},"id":"LprCHRM2aWb8","outputId":"3377113e-6825-4977-bf5d-ac9c08887b56","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                   text  label\n","0     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","1     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","2     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","3     106 Jan 1 11299 100 1885 107 1771 100 74 79 20...      0\n","4     The race for DNC Chairman was of course totall...      4\n","...                                                 ...    ...\n","9995  his life No he cant Its horribly traumatizing ...      0\n","9996  been called into question by environmental cam...      4\n","9997  college and his 20yearold son Duffy The three ...      2\n","9998  college and his 20yearold son Duffy The three ...      2\n","9999  Brown8217s confederate Chu had connections to ...      4\n","\n","[10000 rows x 2 columns]\n"]}],"source":["summarized_data = pd.DataFrame(texts,\n","               columns =['text'])\n","summarized_data['label'] = labels\n","print(summarized_data)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T16:59:02.489836Z","iopub.status.busy":"2023-06-10T16:59:02.489568Z","iopub.status.idle":"2023-06-10T16:59:02.497290Z","shell.execute_reply":"2023-06-10T16:59:02.495326Z","shell.execute_reply.started":"2023-06-10T16:59:02.489813Z"},"id":"VoY1gHZoaZmG","trusted":true},"outputs":[],"source":["def create_model():\n","    inps = Input(shape = (max_len,), dtype='int64')\n","    masks= Input(shape = (max_len,), dtype='int64')\n","    dbert_layer = dbert_model(inps, attention_mask=masks)[0][:,0,:]\n","    dense_0 = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))(dbert_layer)\n","    dropout_0= Dropout(0.5)(dense_0)\n","    pred = Dense(5, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout_0)\n","    model = tf.keras.Model(inputs=[inps,masks], outputs=pred)\n","    print(model.summary())\n","    return model   "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T16:59:02.499534Z","iopub.status.busy":"2023-06-10T16:59:02.498861Z","iopub.status.idle":"2023-06-10T17:20:11.395110Z","shell.execute_reply":"2023-06-10T17:20:11.393815Z","shell.execute_reply.started":"2023-06-10T16:59:02.499502Z"},"id":"x9kO4eVwCHKg","outputId":"a3776971-f469-4ae7-dd89-06b3b2630cf1","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)solve/main/vocab.txt: 232kB [00:00, 3.05MB/s]"]},{"name":"stderr","output_type":"stream","text":["\n","Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 7.43kB/s]\n","Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 814kB/s]\n","Downloading model.safetensors: 100%|██████████| 440M/440M [00:03<00:00, 112MB/s] \n","2023-06-25 15:43:31.398505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.416332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.416470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.416853: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-25 15:43:31.418357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.418487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.418573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.829324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.829463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.829557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-06-25 15:43:31.829651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20788 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:06:00.0, compute capability: 8.6\n","2023-06-25 15:43:32.839653: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]',                \n","                                thPoolingAndCrossAt               'input_2[0][0]']                \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 512,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 512)          393728      ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 512)          0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 5)            2565        ['dropout_37[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,878,533\n","Trainable params: 109,878,533\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Sun Jun 25 15:45:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n","|  0%   42C    P0    58W / 150W |  21548MiB / 23028MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A     71332      C   ...conda/envs/nlp/bin/python    21546MiB |\n","+-----------------------------------------------------------------------------+\n","Epoch 1/5\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","1125/1125 [==============================] - 349s 305ms/step - loss: 5.5766 - accuracy: 0.8599 - val_loss: 4.3514 - val_accuracy: 0.9100\n","Epoch 2/5\n","1125/1125 [==============================] - 361s 321ms/step - loss: 3.5440 - accuracy: 0.9106 - val_loss: 2.8289 - val_accuracy: 0.9170\n","Epoch 3/5\n","1125/1125 [==============================] - 352s 313ms/step - loss: 2.2451 - accuracy: 0.9376 - val_loss: 1.9517 - val_accuracy: 0.9230\n","Epoch 4/5\n","1125/1125 [==============================] - 362s 322ms/step - loss: 1.4039 - accuracy: 0.9648 - val_loss: 1.3100 - val_accuracy: 0.9310\n","Epoch 5/5\n","1125/1125 [==============================] - 352s 313ms/step - loss: 0.8696 - accuracy: 0.9766 - val_loss: 0.9692 - val_accuracy: 0.9240\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," input_4 (InputLayer)           [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_3[0][0]',                \n","                                thPoolingAndCrossAt               'input_4[0][0]']                \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 512,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model[1][0]']          \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_2 (Dense)                (None, 512)          393728      ['tf.__operators__.getitem_1[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 512)          0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 5)            2565        ['dropout_38[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 109,878,533\n","Trainable params: 109,878,533\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Accuracy: 0.931\n","Weighted F1: 0.9234656159513318\n","Micro F1: 0.931\n","Weighted Precision: 0.9313977502760398\n","Micro Precision: 0.931\n","Weighted Recall: 0.931\n","Micro Recall: 0.931\n"]}],"source":["from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","total_accuracy=0\n","total_weighted_f1=0\n","total_micro_f1=0\n","total_weighted_precision=0\n","total_micro_precision=0\n","total_weighted_recall=0\n","total_micro_recall=0\n","\n","for i in range(1):\n","    gc.collect()\n","    tf.keras.backend.clear_session()\n","    dbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    dbert_model = TFBertModel.from_pretrained('bert-base-uncased')\n","    max_len=512\n","    sentences=summarized_data['text']\n","    labels=summarized_data['label']\n","    len(sentences),len(labels)\n","    model_0=create_model()\n","    input_ids=[]\n","    attention_masks=[]\n","\n","    for sent in sentences:\n","        dbert_inps=dbert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =max_len,pad_to_max_length = True,return_attention_mask = True,truncation=True)\n","        input_ids.append(dbert_inps['input_ids'])\n","        attention_masks.append(dbert_inps['attention_mask'])\n","    input_ids=np.asarray(input_ids)\n","\n","    attention_masks=np.array(attention_masks)\n","    labels=np.array(labels)\n","    train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.1,random_state=42)\n","    log_dir='dbert_model'\n","\n","    model_save_path='/home/ubuntu/HyperPartisan_Classification_Using_BERT/Best512' + str(i) + '-5labels.h5'\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    accuracy = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","    callbacks= [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,monitor='val_accuracy',mode='max',save_best_only=True,save_weights_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n","    model_0.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n","    gpu_info = !nvidia-smi\n","    gpu_info = '\\n'.join(gpu_info)\n","    if gpu_info.find('failed') >= 0:\n","        print('Not connected to a GPU')\n","    else:\n","        print(gpu_info)\n","    history=model_0.fit([train_inp,train_mask],train_label,batch_size=8,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)\n","    pred_labels=[]\n","\n","    model_saved= create_model()\n","    model_saved.compile(loss=loss,optimizer=optimizer, metrics=[accuracy])\n","    model_saved.load_weights('/home/ubuntu/HyperPartisan_Classification_Using_BERT/Best512' + str(i) + '-5labels.h5')\n","\n","    for i in range(0,len(val_inp)):\n","        pred=model_saved.predict([val_inp[i].reshape(1,512),val_mask[i].reshape(1,512)])\n","        pred_label = pred.argmax(axis=1)\n","        pred_labels.append(pred_label)\n","    accuracy=accuracy_score(val_label, pred_labels)\n","    print(\"Accuracy: \"+str(accuracy))\n","    total_accuracy=total_accuracy+accuracy\n","  \n","    weighted_f1=f1_score(val_label,pred_labels, average='weighted')\n","    print(\"Weighted F1: \"+ str(weighted_f1))\n","    total_weighted_f1=total_weighted_f1+weighted_f1\n","    micro_f1=f1_score(val_label,pred_labels, average='micro')\n","    print(\"Micro F1: \"+ str(micro_f1))\n","    total_micro_f1=total_micro_f1+micro_f1\n","\n","    weighted_precision=precision_score(val_label, pred_labels, average='weighted')\n","    print(\"Weighted Precision: \" + str(weighted_precision))\n","    total_weighted_precision=total_weighted_precision+weighted_precision\n","    micro_precision=precision_score(val_label, pred_labels, average='micro')\n","    print(\"Micro Precision: \" + str(micro_precision))\n","    total_micro_precision=total_micro_precision+micro_precision\n","\n","    weighted_recall=recall_score(val_label, pred_labels, average='weighted')\n","    print(\"Weighted Recall: \" + str(weighted_recall))\n","    total_weighted_recall=total_weighted_recall+weighted_recall\n","    micro_recall=recall_score(val_label, pred_labels, average='micro')\n","    print(\"Micro Recall: \" + str(micro_recall))\n","    total_micro_recall=total_micro_recall+micro_recall"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Average Accuracy: 0.931\n","Average Weighted F1: 0.9234656159513318\n","Average Micro F1: 0.931\n","Average Weighted Precision: 0.9313977502760398\n","Average Micro Precision: 0.931\n","Average Weighted Recall: 0.931\n","Average Micro Recall: 0.931\n"]}],"source":["print(\"Average Accuracy: \"+str(total_accuracy/1))\n","print(\"Average Weighted F1: \"+str(total_weighted_f1/1))\n","print(\"Average Micro F1: \"+str(total_micro_f1/1))\n","print(\"Average Weighted Precision: \"+str(total_weighted_precision/1))\n","print(\"Average Micro Precision: \"+str(total_micro_precision/1))\n","print(\"Average Weighted Recall: \"+str(total_weighted_recall/1))\n","print(\"Average Micro Recall: \"+str(total_micro_recall/1))"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Best-512_0:512_15labels.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"}},"nbformat":4,"nbformat_minor":4}
